{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Latent Neural ODEs \u2014 Irregular Time Series Lab\n",
        "**Learning objectives**\n",
        "- Implement the variational latent ODE where $q_\\phi(z_0 \\mid \\{x_t, t_t\\})$ infers an initial latent state and $\\dot{z} = f_\\theta(z, t)$ describes its dynamics\n",
        "- Reproduce the Archimedean spiral dataset used in `torchdiffeq/examples/latent_ode.py`\n",
        "- Train an ODE-RNN encoder + Neural ODE decoder pair that handles irregular samples\n",
        "- Compare posterior sampling, interpolation, and extrapolation to understand how the latent space behaves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "id": "516996d5",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/07-neural-ode/latent-ode.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Why latent ODEs?\n",
        "Regular Neural ODEs assume dense, regularly sampled trajectories with known initial states. The latent ODE treats each sequence as a sample from a continuous-time VAE:\n",
        "1. Sample $z_0 \\sim \\mathcal{N}(0, I)$.\n",
        "2. Evolve $z(t)$ by solving $\\dot{z} = f_\\theta(z, t)$, so $z(t) = z_0 + \\int_{t_0}^{t} f_\\theta(z(\\tau), \\tau)\\,d\\tau$.\n",
        "3. Decode each latent state with $p_\\psi(x_t \\mid z_t) = \\mathcal{N}(g_\\psi(z_t), \\sigma^2 I)$ to obtain observations.\n",
        "4. Use an ODE-RNN encoder $q_\\phi(z_0 \\mid \\{x_t, t_t\\})$ that scans the irregular samples backward in time to amortize inference.\n",
        "\n",
        "This mirrors the course style from the PINNs/DeepONet modules: intuition first, implementation next, experiments last.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Environment setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "REPO_ROOT = Path.cwd()\n",
        "TORCHDIFFEQ_DIR = (REPO_ROOT / 'docs' / '07-neural-ode' / 'torchdiffeq').resolve()\n",
        "if TORCHDIFFEQ_DIR.exists() and str(TORCHDIFFEQ_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(TORCHDIFFEQ_DIR))\n",
        "\n",
        "from torchdiffeq import odeint, odeint_adjoint\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams.update({'axes.grid': True, 'figure.figsize': (6, 4)})\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    npr.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generate the spiral dataset\n",
        "We reuse the exact data generator from `torchdiffeq/examples/latent_ode.py`: two Archimedean spirals whose radius obeys $r(\\theta) = a + b\\theta$ (counter-clockwise) or $r(\\theta) = a + \\frac{50b}{\\theta_{\\max}+1-\\theta}$ (clockwise). Random start indices and additive Gaussian noise make the observations irregular and challenging. Each trajectory contains the full underlying path `orig_trajs`; the model only sees noisy snippets `samp_trajs` with associated timestamps `samp_ts`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def generate_spiral_dataset(nspiral=512, ntotal=1000, nsample=100,\n",
        "                            start=0.0, stop=6 * np.pi, noise_std=0.3,\n",
        "                            a=0.0, b=0.3):\n",
        "    orig_ts = np.linspace(start, stop, num=ntotal)\n",
        "    samp_ts = orig_ts[:nsample]\n",
        "\n",
        "    zs_cw = stop + 1.0 - orig_ts\n",
        "    rs_cw = a + b * 50.0 / zs_cw\n",
        "    cw = np.stack((rs_cw * np.cos(zs_cw) - 5.0, rs_cw * np.sin(zs_cw)), axis=1)\n",
        "\n",
        "    zs_cc = orig_ts\n",
        "    rs_cc = a + b * zs_cc\n",
        "    cc = np.stack((rs_cc * np.cos(zs_cc) + 5.0, rs_cc * np.sin(zs_cc)), axis=1)\n",
        "\n",
        "    orig_trajs = []\n",
        "    samp_trajs = []\n",
        "    for _ in range(nspiral):\n",
        "        t0_idx = npr.randint(nsample, ntotal - nsample)\n",
        "        template = cc if npr.rand() > 0.5 else cw\n",
        "        orig_trajs.append(template)\n",
        "        window = template[t0_idx:t0_idx + nsample, :].copy()\n",
        "        window += npr.randn(*window.shape) * noise_std\n",
        "        samp_trajs.append(window)\n",
        "\n",
        "    return (\n",
        "        np.stack(orig_trajs, axis=0),\n",
        "        np.stack(samp_trajs, axis=0),\n",
        "        orig_ts,\n",
        "        samp_ts,\n",
        "    )\n",
        "\n",
        "orig_trajs, samp_trajs, orig_ts, samp_ts = generate_spiral_dataset()\n",
        "orig_trajs.shape, samp_trajs.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_spirals(orig, samples):\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    ax.plot(orig[0, :, 0], orig[0, :, 1], label='true trajectory', alpha=0.7)\n",
        "    ax.scatter(samples[0, :, 0], samples[0, :, 1], s=10, label='noisy samples')\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('y')\n",
        "    ax.legend()\n",
        "    ax.set_title('Sampled Archimedean spiral (train target)')\n",
        "    plt.show()\n",
        "\n",
        "plot_spirals(orig_trajs, samp_trajs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Preparing tensors and mini-batches\n",
        "We treat every trajectory as a batch element (no shuffling for simplicity). The recognition network consumes observations in reverse chronological order, matching the ODE-RNN design that conditions on future information when inferring $z_0$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "orig_trajs = torch.from_numpy(orig_trajs).float().to(DEVICE)\n",
        "samp_trajs = torch.from_numpy(samp_trajs).float().to(DEVICE)\n",
        "samp_ts = torch.from_numpy(samp_ts).float().to(DEVICE)\n",
        "orig_ts = torch.from_numpy(orig_ts).float().to(DEVICE)\n",
        "\n",
        "BATCH = samp_trajs.shape[0]\n",
        "obs_dim = samp_trajs.shape[-1]\n",
        "print('BATCH', BATCH, 'obs dim', obs_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model components\n",
        "We implement the three learnable blocks required by the latent-ODE architecture:\n",
        "- `LatentODEFunc`: latent vector field $f_\\theta$.\n",
        "- `EncoderRNN`: ODE-RNN recognition model that outputs mean/log-variance of $q(z_0 \\mid \\{x_t\\})$.\n",
        "- `Decoder`: likelihood model $p(x_t \\mid z_t)$ (Gaussian with fixed variance).\n",
        "\n",
        "Initialization mirrors the official implementation but with clearer modules for notebook readability.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class LatentODEFunc(nn.Module):\n",
        "    def __init__(self, latent_dim=6, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Linear(hidden_dim, latent_dim),\n",
        "        )\n",
        "        self.nfe = 0\n",
        "\n",
        "    def forward(self, t, z):\n",
        "        self.nfe += 1\n",
        "        return self.net(z)\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, latent_dim=6, obs_dim=2, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.i2h = nn.Linear(obs_dim + hidden_dim, hidden_dim)\n",
        "        self.h2out = nn.Linear(hidden_dim, 2 * latent_dim)\n",
        "\n",
        "    def forward(self, obs_seq):\n",
        "        h = torch.zeros(obs_seq.size(0), self.hidden_dim, device=obs_seq.device)\n",
        "        for t in reversed(range(obs_seq.size(1))):\n",
        "            obs = obs_seq[:, t, :]\n",
        "            inp = torch.cat([obs, h], dim=-1)\n",
        "            h = torch.tanh(self.i2h(inp))\n",
        "        stats = self.h2out(h)\n",
        "        mean, logvar = torch.chunk(stats, 2, dim=-1)\n",
        "        return mean, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim=6, obs_dim=2, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, obs_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Variational helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def reparameterize(mean, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mean + eps * std\n",
        "\n",
        "\n",
        "def log_normal_pdf(x, mean, logvar):\n",
        "    return -0.5 * (np.log(2 * np.pi) + logvar + (x - mean) ** 2 / torch.exp(logvar))\n",
        "\n",
        "\n",
        "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
        "    v1 = torch.exp(logvar1)\n",
        "    v2 = torch.exp(logvar2)\n",
        "    return 0.5 * (logvar2 - logvar1 + (v1 + (mean1 - mean2) ** 2) / v2 - 1.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ELBO objective\n",
        "The training signal is the negative evidence lower bound\n",
        "$$\\mathcal{L}_{\\text{ELBO}} = -\\mathbb{E}_{q_\\phi(z_0 \\mid x_{1:T})}\\Big[\\sum_{t=1}^T \\log p_\\psi(x_t \\mid z_t)\\Big] + \\mathrm{KL}\\big(q_\\phi(z_0 \\mid x_{1:T}) \\parallel p(z_0)\\big),$$\n",
        "where $p(z_0) = \\mathcal{N}(0, I)$ and $z_t$ is produced by solving $\\dot{z} = f_\\theta(z, t)$ with initial condition $z_0$. Because $p_\\psi(x_t \\mid z_t)$ is Gaussian with variance $\\sigma^2 I$, the reconstruction term reduces to a scaled mean-squared error. The KL term has the closed-form expression shown below, penalizing deviations between the encoder\u2019s posterior and the prior. This objective encourages faithful reconstructions while keeping the latent trajectory well behaved.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class LatentODEModel(nn.Module):\n",
        "    def __init__(self, latent_dim=6, hidden_dim=64, obs_dim=2, noise_std=0.3,\n",
        "                 solver='dopri5', use_adjoint=False, rtol=1e-5, atol=1e-6):\n",
        "        super().__init__()\n",
        "        self.func = LatentODEFunc(latent_dim, hidden_dim)\n",
        "        self.encoder = EncoderRNN(latent_dim, obs_dim, hidden_dim)\n",
        "        self.decoder = Decoder(latent_dim, obs_dim, hidden_dim)\n",
        "        self.noise_logvar = torch.tensor(np.log(noise_std ** 2), dtype=torch.float32)\n",
        "        self.solver = solver\n",
        "        self.use_adjoint = use_adjoint\n",
        "        self.rtol = rtol\n",
        "        self.atol = atol\n",
        "\n",
        "    def forward(self, obs_seq, t_obs):\n",
        "        q_mean, q_logvar = self.encoder(obs_seq)\n",
        "        z0 = reparameterize(q_mean, q_logvar)\n",
        "        solver = odeint_adjoint if self.use_adjoint else odeint\n",
        "        z_traj = solver(self.func, z0, t_obs, method=self.solver,\n",
        "                        rtol=self.rtol, atol=self.atol)\n",
        "        z_traj = z_traj.permute(1, 0, 2)\n",
        "        x_pred = self.decoder(z_traj)\n",
        "        return x_pred, q_mean, q_logvar, z0\n",
        "\n",
        "    def elbo(self, obs_seq, t_obs):\n",
        "        x_pred, q_mean, q_logvar, _ = self.forward(obs_seq, t_obs)\n",
        "        noise_logvar = self.noise_logvar.to(obs_seq.device)\n",
        "        recon_logprob = log_normal_pdf(obs_seq, x_pred, noise_logvar)\n",
        "        recon_term = recon_logprob.sum(dim=[1, 2])\n",
        "        prior_mean = torch.zeros_like(q_mean)\n",
        "        prior_logvar = torch.zeros_like(q_logvar)\n",
        "        kl = normal_kl(q_mean, q_logvar, prior_mean, prior_logvar).sum(dim=1)\n",
        "        elbo = recon_term - kl\n",
        "        return -elbo.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_latent_ode(model, data, t_obs, niters=2000, lr=1e-2, eval_every=100):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    losses = []\n",
        "    iters = []\n",
        "    for itr in range(1, niters + 1):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.elbo(data, t_obs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if itr % eval_every == 0:\n",
        "            losses.append(loss.item())\n",
        "            iters.append(itr)\n",
        "            print(f\"Iter {itr:04d} | -ELBO {loss.item():.4f}\")\n",
        "    return {'iters': iters, 'losses': losses}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "set_seed(1)\n",
        "latent_model = LatentODEModel(latent_dim=6, hidden_dim=64, obs_dim=obs_dim,\n",
        "                              noise_std=0.3, solver='dopri5', use_adjoint=False).to(DEVICE)\n",
        "training_log = train_latent_ode(latent_model, samp_trajs, samp_ts, niters=1500, lr=1e-2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(training_log['iters'], training_log['losses'], marker='o')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('-ELBO')\n",
        "plt.title('Latent ODE training curve')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Posterior sampling & reconstruction\n",
        "We draw $z_0 \\sim q(z_0 \\mid x)$, integrate both forward and backward in time, and decode to observation space to illustrate interpolation/extrapolation just like Fig. 3 in the paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def posterior_sample(model, obs_seq, t_obs, t_full_pos, t_full_neg):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        q_mean, q_logvar = model.encoder(obs_seq)\n",
        "        z0 = q_mean[0]\n",
        "        solver = odeint_adjoint if model.use_adjoint else odeint\n",
        "        z_pos = solver(model.func, z0, t_full_pos, method=model.solver,\n",
        "                       rtol=model.rtol, atol=model.atol)\n",
        "        z_neg = solver(model.func, z0, t_full_neg, method=model.solver,\n",
        "                       rtol=model.rtol, atol=model.atol)\n",
        "        x_pos = model.decoder(z_pos)\n",
        "        x_neg = model.decoder(z_neg)\n",
        "    return x_pos.cpu(), x_neg.cpu()\n",
        "\n",
        "long_ts_pos = torch.linspace(0.0, 2 * np.pi, 2000, device=DEVICE)\n",
        "long_ts_neg = torch.linspace(-np.pi, 0.0, 1000, device=DEVICE)\n",
        "x_pos, x_neg = posterior_sample(latent_model, samp_trajs, samp_ts, long_ts_pos, long_ts_neg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def plot_latent_recon(orig, samples, pos, neg):\n",
        "    orig_np = orig[0].cpu().numpy()\n",
        "    samp_np = samples[0].cpu().numpy()\n",
        "    pos_np = pos.numpy()\n",
        "    neg_np = torch.flip(neg, dims=[0]).numpy()\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(orig_np[:, 0], orig_np[:, 1], 'g', label='true trajectory')\n",
        "    plt.scatter(samp_np[:, 0], samp_np[:, 1], s=5, c='k', label='noisy samples')\n",
        "    plt.plot(pos_np[:, 0], pos_np[:, 1], 'r', label='model t>0')\n",
        "    plt.plot(neg_np[:, 0], neg_np[:, 1], 'c', label='model t<0')\n",
        "    plt.legend()\n",
        "    plt.title('Latent ODE interpolation/extrapolation')\n",
        "    plt.show()\n",
        "\n",
        "plot_latent_recon(orig_trajs, samp_trajs, x_pos, x_neg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Handling irregular timestamps\n",
        "Because `odeint` accepts arbitrary evaluation grids, we can subsample random timestamps per trajectory. The encoder only sees available points; the decoder still generates a dense trajectory at `samp_ts`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def random_time_mask(data, drop_prob=0.3):\n",
        "    mask = torch.rand_like(data[..., 0]) > drop_prob\n",
        "    masked = data.clone()\n",
        "    masked[~mask] = 0.0\n",
        "    return masked, mask\n",
        "\n",
        "masked_obs, mask = random_time_mask(samp_trajs, drop_prob=0.5)\n",
        "masked_loss = latent_model.elbo(masked_obs, samp_ts)\n",
        "print('ELBO with 50% missing points:', masked_loss.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Exercises\n",
        "- **Adjoint vs. standard backprop:** set `use_adjoint=True` to reduce memory and compare wall-clock time.\n",
        "- **Noisy or irregular batches:** sample a different timestamp mask per iteration to mimic ICU data from Section 5.\n",
        "- **Latent dimension sweep:** try latent dimensions {4, 8, 16} and report ELBO / reconstruction quality.\n",
        "- **VAE diagnostics:** track $\\mathrm{KL}$ separately to monitor posterior collapse, similar to Appendix C of the paper.\n",
        "\n",
        "These prompts match the style of other course sections and encourage deeper experimentation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
