{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d2182cad",
      "metadata": {},
      "source": [
        "# Neural Ordinary Differential Equations — Spiral Dynamics Lab\n",
        "**Learning objectives**\n",
        "- Connect residual networks to continuous-depth dynamics by taking the limit of $h_{t+1} = h_t + \\Delta t\\,f_\\theta(h_t, t)$ as $\\Delta t \\to 0$\n",
        "- Understand how the adjoint state $a(t)$ with dynamics $\\dot{a} = -\\left(\\partial f_\\theta / \\partial h\\right)^{\\top} a$ yields $\\mathcal{O}(1)$-memory training\n",
        "- Reproduce the cubic spiral system defined by $\\dot{z} = A (z \\odot z \\odot z)$ and its mini-batch data loader\n",
        "- Compare solvers, tolerances, and adjoint tricks to design Neural ODE exercises analogous to the PINNs / DeepONet modules\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320d7010",
      "metadata": {},
      "source": [
        "**Solution**: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/07-neural-ode/neural-ode.ipynb)\n",
        "**Exercise**: [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/07-neural-ode/neural-ode-exercise.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41666ecf",
      "metadata": {},
      "source": [
        "## 1. From residual blocks to continuous depth\n",
        "A ResNet layer computes\n",
        "$$h_{t+1} = h_t + f_\\theta(h_t),$$\n",
        "which is exactly a forward-Euler update of the autonomous ODE $\\frac{dh}{dt} = f_\\theta(h)$. Letting the layer spacing $\\Delta t \\to 0$ gives the flow map\n",
        "$$\\phi_{t_0 \\to t_1}(h_0) = h_0 + \\int_{t_0}^{t_1} f_\\theta(h(t), t)\\,dt,$$\n",
        "so deep residual blocks become continuous-depth dynamics. This notebook follows the same pattern used throughout the course: build intuition, implement the model, then explore experiments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4746c05c",
      "metadata": {},
      "source": [
        "## 2. Adjoint method recap\n",
        "To differentiate through an ODE solver efficiently, introduce the adjoint state $a(t) = \\partial \\mathcal{L}/\\partial h(t)$ and the Hamiltonian $\\mathcal{H}(h, a, t) = a^{\\top} f_\\theta(h, t)$. Differentiating the objective with Lagrange multipliers produces the coupled backward dynamics\n",
        "$$\\dot{a}(t) = -\\left(\\frac{\\partial f_\\theta}{\\partial h}(h(t), t)\\right)^{\\top} a(t),$$\n",
        "with terminal condition $a(t_1) = \\partial \\mathcal{L}/\\partial h(t_1)$. Integrating $h(t)$ forward and $(h(t), a(t))$ backward yields gradients while storing only the current state, giving $\\mathcal{O}(1)$ memory regardless of the number of solver steps. We expose both `odeint` and `odeint_adjoint` so you can compare their runtime/memory trade-offs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b3a8bfc",
      "metadata": {},
      "source": [
        "## Variational inference and the ELBO (primer)\n",
        "Latent Neural ODEs and function encoders augment the basic setup with latent variables $z$. The generative model samples $z_0 \\sim p(z_0)$, evolves it via $\\dot{z} = f_\\theta(z, t)$, and decodes observations with $p(x_t \\mid z_t)$. Because the exact posterior $p(z_0 \\mid x_{1:T})$ is intractable, we introduce an encoder distribution $q_\\phi(z_0 \\mid x_{1:T})$ and optimize the evidence lower bound:\n",
        "$$\\log p(x_{1:T}) \\ge \\mathbb{E}_{q_\\phi(z_0 \\mid x_{1:T})}\\left[\\log p_\\theta(x_{1:T} \\mid z_{1:T})\\right] - \\mathrm{KL}\\big(q_\\phi(z_0 \\mid x_{1:T}) \\parallel p(z_0)\\big).$$\n",
        "The first term is a reconstruction log-likelihood, while the second regularizes the inferred initial condition toward the prior. This variational perspective is used directly in the latent-ODE and zero-shot notebooks, so we keep the equations handy here for reference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e431a681",
      "metadata": {},
      "source": [
        "## 3. Environment setup\n",
        "The original `torchdiffeq` repo sits in `docs/07-neural-ode/torchdiffeq`. The helper cell below wires it into `sys.path`, sets deterministic seeds, and establishes some visualization defaults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714d0232",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "plt.rcParams.update({'figure.figsize': (6, 4), 'axes.grid': True})\n",
        "\n",
        "REPO_ROOT = Path.cwd()\n",
        "TORCHDIFFEQ_DIR = (REPO_ROOT / 'docs' / '07-neural-ode' / 'torchdiffeq').resolve()\n",
        "if TORCHDIFFEQ_DIR.exists() and str(TORCHDIFFEQ_DIR) not in sys.path:\n",
        "    sys.path.insert(0, str(TORCHDIFFEQ_DIR))\n",
        "\n",
        "from torchdiffeq import odeint, odeint_adjoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1b47eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57785f67",
      "metadata": {},
      "source": [
        "## 4. Ground-truth spiral system (Section 5.1 example)\n",
        "The spiral benchmark uses the cubic vector field $\\dot{z} = A z^3$ with\n",
        "$$A = \\begin{bmatrix}-0.1 & 2.0\\\\ -2.0 & -0.1\\end{bmatrix}.$$\n",
        "We integrate it with a high-accuracy Dormand–Prince solver (`dopri5`) to create the supervised learning target. Batches contain short trajectory snippets, mimicking the training protocol from `torchdiffeq/examples/ode_demo.py`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68e1d871",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_SIZE = 1000\n",
        "T_END = 25.0\n",
        "BATCH_TIME = 10\n",
        "BATCH_SIZE = 20\n",
        "true_y0 = torch.tensor([[2.0, 0.0]], device=DEVICE)\n",
        "t = torch.linspace(0.0, T_END, DATA_SIZE, device=DEVICE)\n",
        "true_A = torch.tensor([[-0.1, 2.0], [-2.0, -0.1]], device=DEVICE)\n",
        "\n",
        "class SpiralDynamics(nn.Module):\n",
        "    def forward(self, t, y):\n",
        "        return torch.mm(y**3, true_A)\n",
        "\n",
        "with torch.no_grad():\n",
        "    gt_solver = SpiralDynamics().to(DEVICE)\n",
        "    true_y = odeint(gt_solver, true_y0, t, method='dopri5')\n",
        "true_y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a7a882",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_batch(batch_size=BATCH_SIZE, batch_time=BATCH_TIME):\n",
        "    start_ids = np.random.choice(np.arange(DATA_SIZE - batch_time), size=batch_size, replace=False).astype(np.int64)\n",
        "    start_ids_tensor = torch.from_numpy(start_ids).long().to(DEVICE)\n",
        "    batch_y0 = true_y[start_ids_tensor]\n",
        "    batch_t = t[:batch_time]\n",
        "    batch_y = torch.stack([true_y[start_ids_tensor + i] for i in range(batch_time)], dim=0)\n",
        "    return batch_y0, batch_t.to(DEVICE), batch_y, start_ids_tensor\n",
        "\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "def plot_phase(traj, reference=None, title='Phase portrait'):\n",
        "    traj_np = to_numpy(traj)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.plot(traj_np[:, 0, 0], traj_np[:, 0, 1], label='trajectory', linewidth=2)\n",
        "    if reference is not None:\n",
        "        ref_np = to_numpy(reference)\n",
        "        plt.plot(ref_np[:, 0, 0], ref_np[:, 0, 1], '--', label='reference')\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_time_series(times, traj, reference=None, title='State vs time'):\n",
        "    t_np = to_numpy(times)\n",
        "    traj_np = to_numpy(traj)\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(t_np, traj_np[:, 0, 0], label='x(t)')\n",
        "    plt.plot(t_np, traj_np[:, 0, 1], label='y(t)')\n",
        "    if reference is not None:\n",
        "        ref_np = to_numpy(reference)\n",
        "        plt.plot(t_np, ref_np[:, 0, 0], '--', label='x true')\n",
        "        plt.plot(t_np, ref_np[:, 0, 1], '--', label='y true')\n",
        "    plt.xlabel('time')\n",
        "    plt.ylabel('state value')\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3985cdc",
      "metadata": {},
      "source": [
        "### Visualize the supervised signal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36f34616",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_phase(true_y, title='Ground-truth spiral (cubic system)')\n",
        "plot_time_series(t, true_y, title='Ground-truth trajectories')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9422929",
      "metadata": {},
      "source": [
        "## 5. Neural ODE parametrization\n",
        "We learn a neural vector field $f_\\theta(z)$ such that $\\dot{z} = f_\\theta(z)$ matches the true system. The function is a small MLP following the architecture in the paper (50 hidden units + Tanh). We wrap it in a `NeuralODEModel` that can use either `odeint` or `odeint_adjoint`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f08feecf",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ODEFunc(nn.Module):\n",
        "\n",
        "\n",
        "\n",
        "class NeuralODEModel(nn.Module):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b1fef4",
      "metadata": {},
      "source": [
        "## 6. Training utilities\n",
        "Following the paper, we optimize the $L_1$ loss between predicted and true trajectories. Each iteration samples a mini-batch of time windows so the model learns local dynamics instead of memorizing one trajectory. Logs store both batch losses and full-trajectory validation losses for plotting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fbceb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_neural_ode(model, num_iters=1500, lr=1e-3, eval_freq=100):\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "    history = []\n",
        "    batch_losses = []\n",
        "    start = time.time()\n",
        "    for itr in range(1, num_iters + 1):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        if itr % eval_freq == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                pred_full = model(true_y0, t)\n",
        "                eval_loss = torch.mean(torch.abs(pred_full - true_y)).item()\n",
        "            history.append({'iter': itr, 'train_loss': loss.item(), 'eval_loss': eval_loss})\n",
        "            print(f\"Iter {itr:04d} | batch L1 {loss.item():.5f} | full traj L1 {eval_loss:.5f}\")\n",
        "    elapsed = time.time() - start\n",
        "    return {'history': history, 'batch_losses': batch_losses, 'elapsed': elapsed}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a7d1f1",
      "metadata": {},
      "source": [
        "## 7. Fit the neural ODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0cfd55",
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(1)\n",
        "neural_ode = NeuralODEModel(hidden_dim=64, method='dopri5', rtol=1e-5, atol=1e-6, use_adjoint=False).to(DEVICE)\n",
        "training_stats = train_neural_ode(neural_ode, num_iters=1500, eval_freq=100)\n",
        "training_stats['elapsed']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26bc720f",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7, 4))\n",
        "plt.plot(training_stats['batch_losses'], label='mini-batch L1')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training loss trace')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "iters = [h['iter'] for h in training_stats['history']]\n",
        "full_losses = [h['eval_loss'] for h in training_stats['history']]\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(iters, full_losses, marker='o')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('full trajectory L1')\n",
        "plt.title('Validation trajectory error')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "924a1994",
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_ode.eval()\n",
        "with torch.no_grad():\n",
        "    pred_traj = neural_ode(true_y0, t)\n",
        "plot_time_series(t, pred_traj, reference=true_y, title='Neural ODE vs ground truth (time domain)')\n",
        "plot_phase(pred_traj, reference=true_y, title='Neural ODE vs ground truth (phase space)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ca4c4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_vector_field(func, title='Learned vector field'):\n",
        "    grid_x = np.linspace(-2, 2, 25)\n",
        "    grid_y = np.linspace(-2, 2, 25)\n",
        "    X, Y = np.meshgrid(grid_x, grid_y)\n",
        "    grid = torch.tensor(np.stack([X, Y], axis=-1).reshape(-1, 2), dtype=torch.float32, device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        vec = func(0, grid).detach().cpu().numpy()\n",
        "    U = vec[:, 0].reshape(X.shape)\n",
        "    V = vec[:, 1].reshape(Y.shape)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    plt.streamplot(X, Y, U, V, color=np.hypot(U, V), cmap='viridis')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "plot_vector_field(neural_ode.func, title='Vector field learned by Neural ODE')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d44910",
      "metadata": {},
      "source": [
        "## 8. Fixed-step ResNet baseline\n",
        "To mirror the pedagogical approach in the PINNs/DeepONet modules, we compare against a discrete residual network that performs explicit-Euler updates with a learned $f_\\theta$. Unlike the Neural ODE, it cannot adapt step sizes or evaluate at arbitrary timestamps, so extrapolation should degrade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca73fa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "class FixedStepResNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=64, max_steps=2000):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.ModuleList([self._make_block(hidden_dim) for _ in range(max_steps)])\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_block(hidden_dim):\n",
        "        block = nn.Sequential(\n",
        "            nn.Linear(2, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 2)\n",
        "        )\n",
        "        for m in block.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
        "                nn.init.zeros_(m.bias)\n",
        "        return block\n",
        "\n",
        "    def forward(self, y0, t_eval, start_indices=None):\n",
        "        if start_indices is None:\n",
        "            start_indices = torch.zeros(y0.shape[0], dtype=torch.long, device=y0.device)\n",
        "        traj = [y0]\n",
        "        y = y0\n",
        "        times = t_eval.to(y0.device)\n",
        "        for step in range(1, times.shape[0]):\n",
        "            dt = float((times[step] - times[step - 1]).item())\n",
        "            next_states = []\n",
        "            for b in range(y.shape[0]):\n",
        "                layer_idx = int(start_indices[b].item()) + step - 1\n",
        "                if layer_idx >= len(self.blocks):\n",
        "                    raise IndexError(f\"Layer index {layer_idx} exceeds available blocks\")\n",
        "                block = self.blocks[layer_idx]\n",
        "                current = y[b]\n",
        "                update = block(current.view(1, -1)).view_as(current)\n",
        "                next_states.append(current + update * dt)\n",
        "            y = torch.stack(next_states, dim=0)\n",
        "            traj.append(y)\n",
        "        return torch.stack(traj)\n",
        "\n",
        "\n",
        "def train_resnet(model, num_iters=1500, lr=1e-3, eval_freq=100):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    history = []\n",
        "    for itr in range(1, num_iters + 1):\n",
        "        optimizer.zero_grad()\n",
        "        batch_y0, batch_t, batch_y, start_idx = sample_batch()\n",
        "        pred = model(batch_y0, batch_t, start_indices=start_idx)\n",
        "        loss = torch.mean(torch.abs(pred - batch_y))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if itr % eval_freq == 0:\n",
        "            with torch.no_grad():\n",
        "                zero_idx = torch.zeros(true_y0.shape[0], dtype=torch.long, device=DEVICE)\n",
        "                pred_full = model(true_y0, t, start_indices=zero_idx)\n",
        "                eval_loss = torch.mean(torch.abs(pred_full - true_y)).item()\n",
        "            history.append({'iter': itr, 'eval_loss': eval_loss})\n",
        "            print(f\"[ResNet] Iter {itr:04d} | full traj L1 {eval_loss:.5f}\")\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d48f17",
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(2)\n",
        "resnet_model = FixedStepResNet(hidden_dim=64).to(DEVICE)\n",
        "resnet_history = train_resnet(resnet_model, num_iters=1200, eval_freq=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c9b386",
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    zero_idx = torch.zeros(true_y0.shape[0], dtype=torch.long, device=DEVICE)\n",
        "    resnet_traj = resnet_model(true_y0, t, start_indices=zero_idx)\n",
        "plot_time_series(t, resnet_traj, reference=true_y, title='Fixed-step ResNet vs ground truth')\n",
        "plot_phase(resnet_traj, reference=true_y, title='ResNet phase comparison')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13a03c0a",
      "metadata": {},
      "source": [
        "### Extrapolation stress test\n",
        "Zero-shot Neural ODE studies emphasize evaluating at unseen time horizons. We extend the time grid to $t=35$ and reuse both models without retraining.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496426ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "t_long = torch.linspace(0.0, 35.0, 1400, device=DEVICE)\n",
        "with torch.no_grad():\n",
        "    true_long = odeint(gt_solver, true_y0, t_long, method='dopri5')\n",
        "    ode_long = neural_ode(true_y0, t_long)\n",
        "    zero_idx = torch.zeros(true_y0.shape[0], dtype=torch.long, device=DEVICE)\n",
        "    resnet_long = resnet_model(true_y0, t_long, start_indices=zero_idx)\n",
        "\n",
        "plot_phase(ode_long, reference=true_long, title='Neural ODE extrapolation (t=35)')\n",
        "plot_phase(resnet_long, reference=true_long, title='ResNet extrapolation (t=35)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25e6d54",
      "metadata": {},
      "source": [
        "## 9. Solver & tolerance sweep (exercise scaffold)\n",
        "Students can replicate Table 1 in the Neural ODE paper by varying solvers and tolerances. The helper below runs short trainings so you can measure stability / accuracy without waiting the full 1500 iterations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43200f0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def quick_eval(method='dopri5', rtol=1e-4, atol=1e-5, niters=600):\n",
        "    set_seed(3)\n",
        "    model = NeuralODEModel(hidden_dim=32, method=method, rtol=rtol, atol=atol).to(DEVICE)\n",
        "    stats = train_neural_ode(model, num_iters=niters, eval_freq=200)\n",
        "    final_loss = stats['history'][-1]['eval_loss'] if stats['history'] else None\n",
        "    return {\n",
        "        'method': method,\n",
        "        'rtol': rtol,\n",
        "        'atol': atol,\n",
        "        'final_loss': final_loss,\n",
        "        'time_sec': stats['elapsed']\n",
        "    }\n",
        "\n",
        "experiments = [\n",
        "    {'method': 'dopri5', 'rtol': 1e-5, 'atol': 1e-6},\n",
        "    {'method': 'tsit5', 'rtol': 1e-5, 'atol': 1e-6},\n",
        "    {'method': 'rk4', 'rtol': 1e-4, 'atol': 1e-5},\n",
        "]\n",
        "results = [quick_eval(**cfg) for cfg in experiments]\n",
        "for res in results:\n",
        "    print(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29ea1893",
      "metadata": {},
      "source": [
        "## 10. Adjoint memory experiment\n",
        "Switch to `odeint_adjoint` to reproduce the $\\mathcal{O}(1)$ memory claim. The API stays identical; only the solver call changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb17bde",
      "metadata": {},
      "outputs": [],
      "source": [
        "set_seed(4)\n",
        "adjoint_model = NeuralODEModel(hidden_dim=64, method='dopri5', rtol=1e-5, atol=1e-6, use_adjoint=True).to(DEVICE)\n",
        "adjoint_stats = train_neural_ode(adjoint_model, num_iters=800, eval_freq=100)\n",
        "print(f\"Adjoint training wall time: {adjoint_stats['elapsed']:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9719e015",
      "metadata": {},
      "source": [
        "## 11. Open-ended exercises\n",
        "- **Solver diagnostics:** Extend the sweep to `rk4` with a manually chosen step size (see `torchdiffeq` README) and document when it diverges.\n",
        "- **Noise robustness:** Add Gaussian noise to the observations and re-run the training, borrowing the latent-ODE idea of encoding irregular samples with an ODE-RNN encoder.\n",
        "- **Function encoders:** Use the architecture from `vanderpol-function-encoder.ipynb` to build a zero-shot initializer for the Neural ODE, mirroring the function-encoder approach to transfer dynamics between tasks.\n",
        "- **ODE-RNN hybrid:** Combine the ResNet encoder with a Neural ODE decoder to bridge toward the latent-ODE and zero-shot labs, keeping the curriculum consistent across exercises.\n",
        "\n",
        "These prompts mirror the exercise-driven structure in the PINNs/DeepONet sections and should be expanded into graded problems if needed.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
