{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiPnnDE635Rf"
   },
   "source": [
    "# Fourier Neural Operator: Learning Solution Operators in Spectral Space\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand the connection between CNNs and kernel operators\n",
    "- Master Fourier Transform fundamentals for neural operators\n",
    "- Learn the FNO architecture: spectral convolution layers\n",
    "- Implement FNO for 1D Burgers equation\n",
    "- Apply FNO to 2D Darcy Flow problem\n",
    "- Explore mesh independence and super-resolution capabilities\n",
    "\n",
    "**Exercise:** [![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-F9AB00?style=flat-square&logo=googlecolab)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/05-fno/fno-exercise.ipynb)\n",
    "**Solution:** [![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-F9AB00?style=flat-square&logo=googlecolab)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/05-fno/fno.ipynb)\n",
    "\n",
    "**Slides:** [![View Slides](https://img.shields.io/badge/View-Presentation-yellow?style=flat-square&logo=googleslides&logoColor=white)](https://raw.githubusercontent.com/kks32-courses/sciml/main/docs/05-fno/fno-slides.pdf)\n",
    "\n",
    "**Paper:** [![FNO Paper](https://img.shields.io/badge/View-googledocs-red?style=flat-square&logo=googleslides&logoColor=white)](https://arxiv.org/abs/2010.08895)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9UlA_yZFQoi"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q huggingface_hub h5py scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353,
     "referenced_widgets": [
      "53fcf9adfaff4857b49b48103a9c303f",
      "320e0f664b2645f0bd2a65d384eedcdd",
      "a7fe5b05fe85447a96a22044652f53bd",
      "062a03fc5e50465d80d8bba0a9e0f069",
      "ad359a28b62f4ba98d16d2c54712b722",
      "01d0e629285040eda37643934cd5a3f9",
      "f0ac35ef59804bf89aefa0da653dbdb2",
      "64a773c2e3cc4bbb9d906c543cb65160",
      "cfd3e774555b4a31918e5035ee5db1ae",
      "c0be1e3c355542408ecc2dd9f552e968",
      "1ca565be276842509dd7181177a8bfa5",
      "5eb7f98f15fb48039121703b002db174",
      "a91a6c951c674eba9c38fdb0d9320ec3",
      "7f1493d4f8f84929bd45c1d6c7ef80ce",
      "7f9abd6fbb864122a9e126a01ebd0667",
      "118cf6fe43414a2bab1d739047c6cacd",
      "f674977990e94907a53bb02bfad5a51c",
      "3a0b9bb429cd47a2a9070cd85c013c3e",
      "3e163fbe67b842dd973c161fb8e3a69a",
      "ce194aa06b0843c49c4765990b7f9375",
      "35ea29a5c64943da94e86c9580ef3292",
      "21dff99c1a35448ea19d537d84322852",
      "5b372294fc704509a0c2a557fee2eaa2",
      "7a119ed2ca5c47eda0f014cdfb016fee",
      "96cfd83dc0b548d9ac6592748fe4d197",
      "9cad2a00c94341079c2ec4b4be41bd2c",
      "e4897e3bfc2843e4a2426890a0fdfbc7",
      "039e5d391b6d46e592653bf133220cb7",
      "8c100014093c445a8612a0f019220b09",
      "6946dcff8bb448b68cb31b849e67f12c",
      "805395e5134946cb8703df43eafc3fd0",
      "8079b537994e4bb883b3c2d536fd00b6",
      "2a54ce763bd8416087c3422f3cf32128"
     ]
    },
    "id": "z8LNdg4UFIKt",
    "outputId": "86aadcc4-4d6a-4090-d80d-4bced81ba1e9"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create directories\n",
    "!mkdir -p Darcy_241\n",
    "\n",
    "print(\"Downloading datasets from Hugging Face...\")\n",
    "\n",
    "# Download Burgers data\n",
    "burgers_file = hf_hub_download(\n",
    "    repo_id=\"kks32/sciml-dataset\",\n",
    "    filename=\"fno/burgers_data_R10.mat\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "shutil.copy(burgers_file, \"burgers_data_R10.mat\")\n",
    "\n",
    "# Download Darcy training data\n",
    "darcy_train = hf_hub_download(\n",
    "    repo_id=\"kks32/sciml-dataset\",\n",
    "    filename=\"fno/Darcy_241/piececonst_r241_N1024_smooth1.mat\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "shutil.copy(darcy_train, \"Darcy_241/piececonst_r241_N1024_smooth1.mat\")\n",
    "\n",
    "# Download Darcy test data\n",
    "darcy_test = hf_hub_download(\n",
    "    repo_id=\"kks32/sciml-dataset\",\n",
    "    filename=\"fno/Darcy_241/piececonst_r241_N1024_smooth2.mat\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "shutil.copy(darcy_test, \"Darcy_241/piececonst_r241_N1024_smooth2.mat\")\n",
    "\n",
    "# Download utilities\n",
    "!wget -q https://raw.githubusercontent.com/kks32-courses/sciml/main/docs/05-fno/utilities3.py -O utilities3.py\n",
    "\n",
    "print(\"\\n✅ Setup complete! Data downloaded from Hugging Face.\")\n",
    "print(f\"  Burgers: {os.path.getsize('burgers_data_R10.mat') / 1024**2:.1f} MB\")\n",
    "print(f\"  Darcy train: {os.path.getsize('Darcy_241/piececonst_r241_N1024_smooth1.mat') / 1024**2:.1f} MB\")\n",
    "print(f\"  Darcy test: {os.path.getsize('Darcy_241/piececonst_r241_N1024_smooth2.mat') / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZgaQEGe35Rg"
   },
   "source": [
    "## The Central Challenge\n",
    "\n",
    "We've seen how DeepONet learns operators by decomposing them into branch-trunk architectures.\n",
    "\n",
    "**But there's a deeper question:** What if physics itself suggests the right representation?\n",
    "\n",
    "For 50+ years, **spectral methods** based on Fourier transforms have dominated computational physics. They work because:\n",
    "- Many PDEs simplify in Fourier space (convolution → multiplication)\n",
    "- Derivatives become algebraic: $\\mathcal{F}(\\frac{\\partial u}{\\partial x}) = ik\\hat{u}(k)$\n",
    "- Global information propagates naturally\n",
    "\n",
    "**The FNO insight:** Learn operators *in Fourier space* rather than physical space.\n",
    "\n",
    "$$\\text{Input} \\xrightarrow{\\text{FFT}} \\text{Fourier Space} \\xrightarrow{\\text{Learn}} \\text{Fourier Space} \\xrightarrow{\\text{IFFT}} \\text{Output}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RShSJeVy35Rh",
    "outputId": "96ff6f3b-4122-4275-b2cd-aced114602c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add fourier_neural_operator to path for utilities\n",
    "from utilities3 import MatReader, UnitGaussianNormalizer, LpLoss, count_params\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device selection\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using CUDA GPU\")\n",
    "        return device\n",
    "    elif torch.backends.mps.is_available():\n",
    "        # MPS has issues with complex FFT operations, causing slow CPU↔MPS transfers\n",
    "        # For FNO, CPU is often faster than MPS due to FFT overhead\n",
    "        print(\"Apple Silicon detected, but using CPU for better FFT performance\")\n",
    "        print(\"(MPS has overhead with complex FFT operations)\")\n",
    "        return torch.device(\"cpu\")\n",
    "    else:\n",
    "        print(\"Using CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Device: {device}\")\n",
    "print(\"Training will be optimized for this device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOotHeT335Ri"
   },
   "source": [
    "## From CNNs to Kernel Operators\n",
    "\n",
    "### Convolutional Neural Networks\n",
    "\n",
    "CNNs apply **local** kernels to extract features:\n",
    "\n",
    "$$(f * g)(x) = \\int_{\\text{local}} f(x') g(x - x') dx'$$\n",
    "\n",
    "![CNN Architecture](figs/cnn.png)\n",
    "\n",
    "**Key properties:**\n",
    "- Translation invariant\n",
    "- Local receptive field\n",
    "- Successful for images\n",
    "\n",
    "![CNN Convolution Operation](figs/cnn-pooling.png)\n",
    "\n",
    "### Kernel Operators: The General Form\n",
    "\n",
    "A kernel operator maps functions to functions:\n",
    "\n",
    "$$\\mathcal{K}(v)(x) = \\int_{\\Omega} \\kappa(x, x') v(x') dx'$$\n",
    "\n",
    "where $\\kappa(x, x')$ is a **learned kernel**.\n",
    "\n",
    "**Types of kernels:**\n",
    "1. **Standard convolution:** $\\kappa(x, x') = k(x - x')$ (local, translation-invariant)\n",
    "2. **Graph operators:** $\\kappa$ defined on graph edges\n",
    "3. **Fourier operators:** $\\kappa$ learned in spectral space (global, efficient)\n",
    "\n",
    "### Why Fourier?\n",
    "\n",
    "**Convolution theorem:** Convolution in physical space = multiplication in Fourier space\n",
    "\n",
    "$$\\mathcal{F}(f * g) = \\mathcal{F}(f) \\cdot \\mathcal{F}(g)$$\n",
    "\n",
    "This means we can:\n",
    "1. Transform to Fourier space (FFT)\n",
    "2. Learn simple multiplication weights\n",
    "3. Transform back (IFFT)\n",
    "\n",
    "**Computational advantage:** FFT is $O(N \\log N)$, far cheaper than dense convolution $O(N^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJ-qm5w435Ri"
   },
   "source": [
    "## Fourier Transform: The Foundation\n",
    "\n",
    "### Mathematical Definition\n",
    "\n",
    "The **Fourier Transform** decomposes a function into sinusoidal components:\n",
    "\n",
    "$$\\hat{u}(k) = \\mathcal{F}(u)(k) = \\int_{-\\infty}^{\\infty} u(x) e^{-ikx} dx$$\n",
    "\n",
    "**Inverse Fourier Transform:**\n",
    "\n",
    "$$u(x) = \\mathcal{F}^{-1}(\\hat{u})(x) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\hat{u}(k) e^{ikx} dk$$\n",
    "\n",
    "**Key insight:** Any function can be written as:\n",
    "\n",
    "$$u(x) = \\sum_{k} \\hat{u}_k e^{ikx}$$\n",
    "\n",
    "where $\\hat{u}_k$ are **Fourier coefficients** (complex weights) and $e^{ikx}$ are basis functions.\n",
    "\n",
    "### Properties\n",
    "\n",
    "1. **Derivatives become multiplication:** $\\mathcal{F}(\\frac{\\partial u}{\\partial x}) = ik\\hat{u}(k)$\n",
    "2. **Convolution becomes multiplication:** $\\mathcal{F}(u * v) = \\mathcal{F}(u) \\cdot \\mathcal{F}(v)$\n",
    "3. **Parseval's theorem:** $\\int |u(x)|^2 dx = \\int |\\hat{u}(k)|^2 dk$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "VK-_d5Kq35Ri",
    "outputId": "0abc9b5c-25f4-4c6d-bdec-4d6cb0eadf28"
   },
   "outputs": [],
   "source": [
    "# Demonstrate Fourier decomposition\n",
    "def demonstrate_fourier():\n",
    "    x = np.linspace(0, 4*np.pi, 1000)\n",
    "\n",
    "    # Create a composite function\n",
    "    f = np.sin(x) + 0.5*np.sin(3*x) + 0.3*np.sin(5*x)\n",
    "\n",
    "    # Compute FFT\n",
    "    f_fft = np.fft.fft(f)\n",
    "    freqs = np.fft.fftfreq(len(x), x[1] - x[0])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "    # Original function\n",
    "    axes[0].plot(x, f, 'b-', linewidth=2)\n",
    "    axes[0].set_title('Function in Physical Space', fontsize=14)\n",
    "    axes[0].set_xlabel('x')\n",
    "    axes[0].set_ylabel('f(x)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Fourier coefficients (magnitude)\n",
    "    axes[1].stem(freqs[:len(freqs)//2], np.abs(f_fft[:len(freqs)//2]), basefmt=' ')\n",
    "    axes[1].set_title('Fourier Coefficients (Magnitude)', fontsize=14)\n",
    "    axes[1].set_xlabel('Frequency k')\n",
    "    axes[1].set_ylabel('|F(k)|')\n",
    "    axes[1].set_xlim([0, 2])\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    # Reconstruction with limited modes\n",
    "    for n_modes in [1, 3, 10]:\n",
    "        f_fft_truncated = f_fft.copy()\n",
    "        f_fft_truncated[n_modes:-n_modes+1] = 0\n",
    "        f_reconstructed = np.fft.ifft(f_fft_truncated).real\n",
    "        axes[2].plot(x, f_reconstructed, linewidth=2, label=f'{n_modes} modes', alpha=0.8)\n",
    "\n",
    "    axes[2].plot(x, f, 'k--', linewidth=1, label='Original', alpha=0.5)\n",
    "    axes[2].set_title('Reconstruction with Limited Modes', fontsize=14)\n",
    "    axes[2].set_xlabel('x')\n",
    "    axes[2].set_ylabel('f(x)')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Key observation: Most energy concentrated in low frequencies\")\n",
    "    print(\"FNO exploits this by learning weights only for low-frequency modes\")\n",
    "\n",
    "demonstrate_fourier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4FJkZ-935Rj"
   },
   "source": [
    "## Fourier Neural Operator Architecture\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "Instead of learning in physical space, **learn in Fourier space**:\n",
    "\n",
    "$$v_{t+1}(x) = \\sigma\\left(W v_t(x) + \\mathcal{K}(v_t)(x)\\right)$$\n",
    "\n",
    "where the kernel operator $\\mathcal{K}$ is parameterized in Fourier space:\n",
    "\n",
    "$$\\mathcal{K}(v)(x) = \\mathcal{F}^{-1}\\left(R_\\phi \\cdot \\mathcal{F}(v)\\right)(x)$$\n",
    "\n",
    "Here, $R_\\phi$ are **learnable weights** in Fourier space.\n",
    "\n",
    "### Complete FNO Architecture\n",
    "\n",
    "![Fourier Neural Operator Architecture](figs/fourier_architecture.png)\n",
    "\n",
    "The architecture consists of:\n",
    "\n",
    "```\n",
    "Input u(x)  [batch, n_points, d_in]\n",
    "    ↓\n",
    "Lifting: P(u) → v₀  [batch, n_points, width]\n",
    "    ↓\n",
    "Fourier Layer 1: v₁ = σ(W₀v₀ + K₀(v₀))\n",
    "Fourier Layer 2: v₂ = σ(W₁v₁ + K₁(v₁))\n",
    "Fourier Layer 3: v₃ = σ(W₂v₂ + K₂(v₂))\n",
    "Fourier Layer 4: v₄ = σ(W₃v₃ + K₃(v₃))\n",
    "    ↓\n",
    "Projection: Q(v₄) → output  [batch, n_points, d_out]\n",
    "```\n",
    "\n",
    "### Spectral Convolution Layer\n",
    "\n",
    "Each Fourier layer performs:\n",
    "\n",
    "1. **FFT:** $\\hat{v} = \\mathcal{F}(v)$\n",
    "2. **Linear transform (truncated):** $\\hat{v}_{\\text{out}}[k] = R_\\phi[k] \\cdot \\hat{v}[k]$ for $k \\leq k_{\\text{max}}$\n",
    "3. **IFFT:** $v_{\\text{out}} = \\mathcal{F}^{-1}(\\hat{v}_{\\text{out}})$\n",
    "\n",
    "**Key design choice:** Only keep low-frequency modes ($k_{\\text{max}} \\approx 12-16$), discard high frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0l9tSpAi35Rj"
   },
   "source": [
    "## 1D Example: Burgers Equation\n",
    "\n",
    "### Problem Formulation\n",
    "\n",
    "The 1D viscous Burgers equation:\n",
    "\n",
    "$$\\frac{\\partial u}{\\partial t} + u\\frac{\\partial u}{\\partial x} = \\nu \\frac{\\partial^2 u}{\\partial x^2}, \\quad x \\in [0, 2\\pi], t \\in [0, T]$$\n",
    "\n",
    "with periodic boundary conditions and initial condition $u(x, 0) = u_0(x)$.\n",
    "\n",
    "**Operator learning task:** Learn the mapping\n",
    "\n",
    "$$\\mathcal{G}: u_0(x) \\mapsto u(x, T)$$\n",
    "\n",
    "from initial condition to solution at time $T$.\n",
    "\n",
    "**Dataset:** 1024 training samples from varied initial conditions, solved using spectral methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "oA_BSzcX35Rj",
    "outputId": "86542476-c3a7-4023-ef18-93403b45c294"
   },
   "outputs": [],
   "source": [
    "# Load Burgers equation data\n",
    "print(\"Loading Burgers equation dataset...\")\n",
    "\n",
    "dataloader = MatReader('burgers_data_R10.mat')\n",
    "x_data = dataloader.read_field('a')  # Initial conditions\n",
    "y_data = dataloader.read_field('u')  # Solutions at T=1\n",
    "\n",
    "print(f\"Data shape: {x_data.shape}\")\n",
    "print(f\"Number of samples: {x_data.shape[0]}\")\n",
    "print(f\"Grid resolution: {x_data.shape[1]}\")\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "sub = 4\n",
    "x_data = x_data[:, ::sub]\n",
    "y_data = y_data[:, ::sub]\n",
    "\n",
    "print(f\"Subsampled resolution: {x_data.shape[1]}\")\n",
    "\n",
    "# Visualize samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "x_grid = np.linspace(0, 2*np.pi, x_data.shape[1])\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i//3, i%3]\n",
    "    ax.plot(x_grid, x_data[i], 'b-', linewidth=2, label='u₀(x)', alpha=0.8)\n",
    "    ax.plot(x_grid, y_data[i], 'r-', linewidth=2, label='u(x,T)', alpha=0.8)\n",
    "    ax.set_title(f'Sample {i+1}')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('u')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c2YKQWg35Rj"
   },
   "source": [
    "### 1D Fourier Neural Operator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tj0CSqS35Rj",
    "outputId": "d239153f-4b08-412c-f78f-d27efb25da0a"
   },
   "outputs": [],
   "source": [
    "class SpectralConv1d(nn.Module):\n",
    "    \"\"\"1D Fourier layer: FFT → Linear transform → IFFT\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, modes):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        # Number of Fourier modes to keep (low-frequency truncation)\n",
    "        self.modes = modes\n",
    "\n",
    "        # Initialize weights with proper scaling\n",
    "        \n",
    "        # Complex-valued weights for Fourier space transformation\n",
    "        # Shape: [in_channels, out_channels, modes]\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x shape [batch, in_channels, n_points]\n",
    "\n",
    "        # Step 1: Apply real FFT (efficient for real-valued inputs)\n",
    "        # Output: x_ft shape [batch, in_channels, n_points//2 + 1] (complex)\n",
    "        \n",
    "\n",
    "        # Step 2: Multiply relevant Fourier modes (learned linear transform in frequency domain)\n",
    "        # Initialize output with zeros\n",
    "        \n",
    "\n",
    "        \n",
    "        # Only transform the first 'modes' frequencies (low-frequency focus)\n",
    "        # This is key to FNO: high frequencies are truncated\n",
    "        # einsum performs: out_ft[b,o,k] = sum_i x_ft[b,i,k] * weights[i,o,k]\n",
    "        \n",
    "\n",
    "\n",
    "        # Step 3: Apply inverse FFT to return to physical space\n",
    "        # Output: x shape [batch, out_channels, n_points] (real-valued)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class FNO1d(nn.Module):\n",
    "    \"\"\"1D Fourier Neural Operator\"\"\"\n",
    "\n",
    "    def __init__(self, modes, width, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.modes = modes      # Number of Fourier modes\n",
    "        self.width = width      # Hidden channel dimension\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Lifting layer: embed input to high-dimensional space\n",
    "        # Input: (u₀(x), x) → 2 channels\n",
    "        # Output: 'width' channels\n",
    "        \n",
    "\n",
    "        # Fourier layers: learn operator in spectral space\n",
    "        \n",
    "\n",
    "\n",
    "        # Skip connections: local operations in physical space\n",
    "        # These complement the global Fourier operations\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Projection layers: map back to output space\n",
    "        \n",
    "        # Final output: 1 channel (solution)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x shape [batch, n_points, 2] where 2 = (u₀(x), x)\n",
    "\n",
    "        # Step 1: Lift to high-dimensional space\n",
    "                                # [batch, n_points, width]\n",
    "        x = x.permute(0, 2, 1)  # [batch, width, n_points] for conv layers\n",
    "\n",
    "        # Step 2: Apply Fourier layers with skip connections\n",
    "        # Each layer: v_{t+1} = σ(W*v_t + K(v_t))\n",
    "        # where K is the spectral convolution\n",
    "        for fourier, conv in zip(self.fourier_layers[:-1], self.conv_layers[:-1]):\n",
    "                                 # Global operation in Fourier space\n",
    "                                 # Local operation in physical space\n",
    "                                 # Combine and activate\n",
    "\n",
    "        # Last layer without activation (linear output)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Step 3: Project to output space\n",
    "        x = x.permute(0, 2, 1)  # [batch, n_points, width]\n",
    "        \n",
    "        \n",
    "                                # [batch, n_points, 1]\n",
    "\n",
    "        return x.squeeze(-1)  # [batch, n_points]\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "modes = 16\n",
    "width = 64\n",
    "model_1d = FNO1d(modes, width).to(device)\n",
    "\n",
    "print(f\"FNO1d Architecture:\")\n",
    "print(f\"- Fourier modes: {modes}\")\n",
    "print(f\"- Hidden width: {width}\")\n",
    "print(f\"- Total parameters: {count_params(model_1d):,}\")\n",
    "print(f\"- Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpzIcKv335Rk"
   },
   "source": [
    "### Training the 1D FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuXn0ICw35Rk",
    "outputId": "a433a638-cde0-4135-b916-a31231d4ea1a"
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "ntrain = 1000\n",
    "ntest = 100\n",
    "batch_size = 20\n",
    "\n",
    "x_train = x_data[:ntrain]\n",
    "y_train = y_data[:ntrain]\n",
    "x_test = x_data[-ntest:]\n",
    "y_test = y_data[-ntest:]\n",
    "\n",
    "# Add spatial coordinates\n",
    "s = x_train.shape[1]\n",
    "grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n",
    "grid = torch.tensor(grid, dtype=torch.float32)\n",
    "\n",
    "x_train = torch.cat([x_train.reshape(ntrain, s, 1), grid.repeat(ntrain, 1, 1)], dim=2)\n",
    "x_test = torch.cat([x_test.reshape(ntest, s, 1), grid.repeat(ntest, 1, 1)], dim=2)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_train, y_train),\n",
    "    batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_test, y_test),\n",
    "    batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {ntrain}\")\n",
    "print(f\"Test samples: {ntest}\")\n",
    "print(f\"Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANR_jNCR35Rk",
    "outputId": "b0323675-7d19-4ab9-b1bf-6b0ea777fe9b"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs = 200  # Reduced from 500 for faster demonstration\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1d.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=learning_rate,\n",
    "    div_factor=1e4, final_div_factor=1e4,\n",
    "    steps_per_epoch=len(train_loader), epochs=epochs\n",
    ")\n",
    "\n",
    "myloss = LpLoss(d=1, p=2, size_average=False)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(f\"Training FNO1d for {epochs} epochs...\")\n",
    "pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    model_1d.train()\n",
    "    train_l2 = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model_1d(x)\n",
    "\n",
    "        loss = myloss(out.view(x.shape[0], -1), y.view(x.shape[0], -1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    # Evaluation\n",
    "    model_1d.eval()\n",
    "    test_l2 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model_1d(x)\n",
    "            test_l2 += myloss(out.view(x.shape[0], -1), y.view(x.shape[0], -1)).item()\n",
    "\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    train_losses.append(train_l2)\n",
    "    test_losses.append(test_l2)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        pbar.set_postfix({'Train L2': f'{train_l2:.6f}', 'Test L2': f'{test_l2:.6f}'})\n",
    "\n",
    "print(f\"Final train loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final test loss: {test_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "7TsFsPWU35Rk",
    "outputId": "6bd78c6c-0622-4c29-f51b-0958887be0eb"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train', alpha=0.8)\n",
    "plt.plot(test_losses, label='Test', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative L2 Loss')\n",
    "plt.title('FNO1d Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EAImelW35Rl"
   },
   "source": [
    "### 1D FNO Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "_UyjLzHI35Rl",
    "outputId": "aac88b5b-1354-426b-c7bf-970edbddfa9e"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model_1d.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get predictions for first 6 test samples\n",
    "    x_plot = x_test[:6].to(device)\n",
    "    y_plot = y_test[:6]\n",
    "    pred_plot = model_1d(x_plot).cpu()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "x_grid = np.linspace(0, 2*np.pi, s)\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i//3, i%3]\n",
    "    ax.plot(x_grid, y_plot[i], 'b-', linewidth=2, label='True', alpha=0.8)\n",
    "    ax.plot(x_grid, pred_plot[i], 'r--', linewidth=2, label='FNO', alpha=0.8)\n",
    "\n",
    "    error = torch.norm(pred_plot[i] - y_plot[i]) / torch.norm(y_plot[i])\n",
    "    ax.set_title(f'Test {i+1}: Rel. error = {error:.4f}')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('u(x,T)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SZJYI7g35Rl"
   },
   "source": [
    "## 2D Example: Darcy Flow\n",
    "\n",
    "### Problem Formulation\n",
    "\n",
    "The 2D Darcy flow equation models steady-state flow in porous media:\n",
    "\n",
    "$$-\\nabla \\cdot (a(x, y) \\nabla u(x, y)) = f(x, y), \\quad (x, y) \\in [0, 1]^2$$\n",
    "\n",
    "with zero boundary conditions: $u|_{\\partial\\Omega} = 0$.\n",
    "\n",
    "**Operator learning task:** Learn the mapping\n",
    "\n",
    "$$\\mathcal{G}: a(x, y) \\mapsto u(x, y)$$\n",
    "\n",
    "from permeability coefficient $a$ to pressure/hydraulic head $u$.\n",
    "\n",
    "**Physical interpretation:**\n",
    "- $a(x, y)$: permeability field (how easily fluid flows)\n",
    "- $u(x, y)$: pressure field\n",
    "- $f(x, y)$: source term (set to 1 in our examples)\n",
    "\n",
    "**Dataset:** 1024 samples with random piecewise constant permeability fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1WWP0XY35Rl",
    "outputId": "27503d63-7fb6-4a8e-964f-b7a3a1a43d4b"
   },
   "outputs": [],
   "source": [
    "# Load Darcy flow data\n",
    "print(\"Loading Darcy flow dataset...\")\n",
    "\n",
    "TRAIN_PATH = 'Darcy_241/piececonst_r241_N1024_smooth1.mat'\n",
    "TEST_PATH = 'Darcy_241/piececonst_r241_N1024_smooth2.mat'\n",
    "\n",
    "# Load training data\n",
    "reader = MatReader(TRAIN_PATH)\n",
    "x_train_2d = reader.read_field('coeff')  # Permeability\n",
    "y_train_2d = reader.read_field('sol')    # Solution\n",
    "\n",
    "# Load test data\n",
    "reader.load_file(TEST_PATH)\n",
    "x_test_2d = reader.read_field('coeff')\n",
    "y_test_2d = reader.read_field('sol')\n",
    "\n",
    "print(f\"Training data shape: {x_train_2d.shape}\")\n",
    "print(f\"Test data shape: {x_test_2d.shape}\")\n",
    "\n",
    "# Subsample for computational efficiency\n",
    "r = 3\n",
    "s_2d = int(((241 - 1) / r) + 1)\n",
    "x_train_2d = x_train_2d[:1000, ::r, ::r][:, :s_2d, :s_2d]\n",
    "y_train_2d = y_train_2d[:1000, ::r, ::r][:, :s_2d, :s_2d]\n",
    "x_test_2d = x_test_2d[:100, ::r, ::r][:, :s_2d, :s_2d]\n",
    "y_test_2d = y_test_2d[:100, ::r, ::r][:, :s_2d, :s_2d]\n",
    "\n",
    "print(f\"Subsampled resolution: {s_2d} × {s_2d}\")\n",
    "print(f\"Training samples: {x_train_2d.shape[0]}\")\n",
    "print(f\"Test samples: {x_test_2d.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "G8pVp1n_35Rl",
    "outputId": "ea9a0943-2b92-45f0-ef3e-527beb563b03"
   },
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for i in range(2):\n",
    "    # Permeability\n",
    "    im1 = axes[i, 0].imshow(x_train_2d[i], cmap='viridis')\n",
    "    axes[i, 0].set_title(f'Sample {i+1}: Permeability a(x,y)')\n",
    "    axes[i, 0].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[i, 0])\n",
    "\n",
    "    # Solution\n",
    "    im2 = axes[i, 1].imshow(y_train_2d[i], cmap='coolwarm')\n",
    "    axes[i, 1].set_title(f'Sample {i+1}: Solution u(x,y)')\n",
    "    axes[i, 1].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[i, 1])\n",
    "\n",
    "    # Permeability (second pair)\n",
    "    im3 = axes[i, 2].imshow(x_train_2d[i+2], cmap='viridis')\n",
    "    axes[i, 2].set_title(f'Sample {i+3}: Permeability a(x,y)')\n",
    "    axes[i, 2].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[i, 2])\n",
    "\n",
    "    # Solution (second pair)\n",
    "    im4 = axes[i, 3].imshow(y_train_2d[i+2], cmap='coolwarm')\n",
    "    axes[i, 3].set_title(f'Sample {i+3}: Solution u(x,y)')\n",
    "    axes[i, 3].axis('off')\n",
    "    plt.colorbar(im4, ax=axes[i, 3])\n",
    "\n",
    "# Hide unused subplot\n",
    "for j in range(4):\n",
    "    axes[2, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Observation: Lower permeability (darker regions) → higher pressure gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQTZ8PJ335Rl"
   },
   "source": [
    "### 2D Fourier Neural Operator Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFge3pCy35Rl",
    "outputId": "5a1e633e-43e4-433a-d4b1-25c0fb43f56d"
   },
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    \"\"\"2D Fourier layer: FFT2 → Linear transform → IFFT2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  # Number of Fourier modes in x-direction\n",
    "        self.modes2 = modes2  # Number of Fourier modes in y-direction\n",
    "\n",
    "        # Initialize weights with proper scaling\n",
    "        self.scale = 1 / (in_channels * out_channels)\n",
    "        \n",
    "        # Two sets of weights for 2D real FFT symmetry\n",
    "        # weights1: for lower-left frequencies\n",
    "        # weights2: for upper-left frequencies (complex conjugate region)\n",
    "        self.weights1 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat)\n",
    "        )\n",
    "        self.weights2 = nn.Parameter(\n",
    "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x shape [batch, in_channels, height, width]\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # Step 1: Apply 2D real FFT\n",
    "        # Output: x_ft shape [batch, in_channels, height, width//2 + 1] (complex)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Step 2: Multiply relevant Fourier modes\n",
    "        # Initialize output Fourier coefficients with zeros\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1)//2 + 1,\n",
    "                            dtype=torch.cfloat, device=x.device)\n",
    "\n",
    "        # Lower frequencies: [0:modes1, 0:modes2]\n",
    "        # These capture smooth, large-scale variations\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = torch.einsum(\n",
    "            \"bixy,ioxy->boxy\",\n",
    "            x_ft[:, :, :self.modes1, :self.modes2],\n",
    "            self.weights1\n",
    "        )\n",
    "\n",
    "        # Higher frequencies (negative): [-modes1:, 0:modes2]\n",
    "        # Due to real FFT symmetry, we need to handle negative frequencies\n",
    "        # These capture finer details at the boundaries\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = torch.einsum(\n",
    "            \"bixy,ioxy->boxy\",\n",
    "            x_ft[:, :, -self.modes1:, :self.modes2],\n",
    "            self.weights2\n",
    "        )\n",
    "\n",
    "        # Step 3: Apply inverse 2D FFT to return to physical space\n",
    "        # Output: x shape [batch, out_channels, height, width] (real-valued)\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    \"\"\"2D Fourier Neural Operator\"\"\"\n",
    "\n",
    "    def __init__(self, modes1, modes2, width, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.modes1 = modes1    # Fourier modes in x\n",
    "        self.modes2 = modes2    # Fourier modes in y\n",
    "        self.width = width      # Hidden channel dimension\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Lifting layer: embed input to high-dimensional space\n",
    "        # Input: (a(x,y), x, y) → 3 channels\n",
    "        # Output: 'width' channels\n",
    "        self.fc0 = nn.Linear(3, width)\n",
    "\n",
    "        # Fourier layers: learn operator in spectral space\n",
    "        self.fourier_layers = nn.ModuleList([\n",
    "            SpectralConv2d(width, width, modes1, modes2) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Skip connections: local operations in physical space\n",
    "        # 1x1 convolutions in spatial domain\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(width, width, 1) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "        # Projection layers: map back to output space\n",
    "        self.fc1 = nn.Linear(width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Final output: 1 channel (pressure field)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input: x shape [batch, height, width, 3] where 3 = (a(x,y), x, y)\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y = x.shape[1], x.shape[2]\n",
    "\n",
    "        # Step 1: Lift to high-dimensional space\n",
    "        x = self.fc0(x)  # [batch, height, width, width_channels]\n",
    "        x = x.permute(0, 3, 1, 2)  # [batch, width_channels, height, width] for conv\n",
    "\n",
    "        # Step 2: Apply Fourier layers with skip connections\n",
    "        # Each layer: v_{t+1} = σ(W*v_t + K(v_t))\n",
    "        for fourier, conv in zip(self.fourier_layers[:-1], self.conv_layers[:-1]):\n",
    "            x1 = fourier(x)  # Global: spectral convolution in Fourier space\n",
    "            # Local: 1x1 conv treating spatial dims as sequence\n",
    "            x2 = conv(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "            x = F.gelu(x1 + x2)  # Combine global and local operations\n",
    "\n",
    "        # Last layer without activation\n",
    "        x1 = self.fourier_layers[-1](x)\n",
    "        x2 = self.conv_layers[-1](x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = x1 + x2\n",
    "\n",
    "        # Step 3: Project to output space\n",
    "        x = x.permute(0, 2, 3, 1)  # [batch, height, width, width_channels]\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)  # [batch, height, width, 1]\n",
    "\n",
    "        return x.squeeze(-1)  # [batch, height, width]\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "modes_2d = 12\n",
    "width_2d = 32\n",
    "model_2d = FNO2d(modes_2d, modes_2d, width_2d).to(device)\n",
    "\n",
    "print(f\"FNO2d Architecture:\")\n",
    "print(f\"- Fourier modes: {modes_2d} × {modes_2d}\")\n",
    "print(f\"- Hidden width: {width_2d}\")\n",
    "print(f\"- Total parameters: {count_params(model_2d):,}\")\n",
    "print(f\"- Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YStaNPWR35Rm"
   },
   "source": [
    "### Training the 2D FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MuLi8CBZ35Rm",
    "outputId": "7301b2ec-190e-4dc7-95d8-d2bb1d61ab53"
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "x_normalizer = UnitGaussianNormalizer(x_train_2d)\n",
    "x_train_2d = x_normalizer.encode(x_train_2d)\n",
    "x_test_2d = x_normalizer.encode(x_test_2d)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(y_train_2d)\n",
    "y_train_2d = y_normalizer.encode(y_train_2d)\n",
    "\n",
    "# Add spatial coordinates\n",
    "grids = []\n",
    "grids.append(np.linspace(0, 1, s_2d))\n",
    "grids.append(np.linspace(0, 1, s_2d))\n",
    "grid_2d = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "grid_2d = grid_2d.reshape(1, s_2d, s_2d, 2)\n",
    "grid_2d = torch.tensor(grid_2d, dtype=torch.float32)\n",
    "\n",
    "x_train_2d = torch.cat([\n",
    "    x_train_2d.reshape(x_train_2d.shape[0], s_2d, s_2d, 1),\n",
    "    grid_2d.repeat(x_train_2d.shape[0], 1, 1, 1)\n",
    "], dim=3)\n",
    "\n",
    "x_test_2d = torch.cat([\n",
    "    x_test_2d.reshape(x_test_2d.shape[0], s_2d, s_2d, 1),\n",
    "    grid_2d.repeat(x_test_2d.shape[0], 1, 1, 1)\n",
    "], dim=3)\n",
    "\n",
    "# Data loaders\n",
    "batch_size_2d = 20\n",
    "train_loader_2d = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_train_2d, y_train_2d),\n",
    "    batch_size=batch_size_2d, shuffle=True\n",
    ")\n",
    "test_loader_2d = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(x_test_2d, y_test_2d),\n",
    "    batch_size=batch_size_2d, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Data prepared for training\")\n",
    "print(f\"Input shape: {x_train_2d.shape}\")\n",
    "print(f\"Output shape: {y_train_2d.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xdg21aW235Rm",
    "outputId": "d326e245-2883-445e-92f7-0a8d502c7c1d"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "epochs_2d = 200  # Reduced from 500 for faster demonstration\n",
    "learning_rate_2d = 0.001\n",
    "\n",
    "optimizer_2d = torch.optim.Adam(model_2d.parameters(), lr=learning_rate_2d, weight_decay=1e-4)\n",
    "scheduler_2d = torch.optim.lr_scheduler.StepLR(optimizer_2d, step_size=50, gamma=0.5)\n",
    "\n",
    "myloss_2d = LpLoss(d=2, p=2, size_average=False)\n",
    "\n",
    "# Move normalizer to device\n",
    "if device.type == 'cuda':\n",
    "    y_normalizer.cuda()\n",
    "elif device.type == 'cpu':\n",
    "    y_normalizer.cpu()\n",
    "\n",
    "# Training loop\n",
    "train_losses_2d = []\n",
    "test_losses_2d = []\n",
    "\n",
    "print(f\"Training FNO2d for {epochs_2d} epochs...\")\n",
    "pbar = tqdm(range(epochs_2d), desc=\"Training\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    model_2d.train()\n",
    "    train_l2 = 0\n",
    "\n",
    "    for x, y in train_loader_2d:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        optimizer_2d.zero_grad()\n",
    "        out = model_2d(x).reshape(batch_size_2d, s_2d, s_2d)\n",
    "        out = y_normalizer.decode(out)\n",
    "        y = y_normalizer.decode(y)\n",
    "\n",
    "        loss = myloss_2d(out.view(batch_size_2d, -1), y.view(batch_size_2d, -1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_2d.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    scheduler_2d.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model_2d.eval()\n",
    "    test_l2 = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader_2d:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model_2d(x).reshape(batch_size_2d, s_2d, s_2d)\n",
    "            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss_2d(out.view(batch_size_2d, -1), y.view(batch_size_2d, -1)).item()\n",
    "\n",
    "    train_l2 /= len(x_train_2d)\n",
    "    test_l2 /= len(x_test_2d)\n",
    "\n",
    "    train_losses_2d.append(train_l2)\n",
    "    test_losses_2d.append(test_l2)\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        pbar.set_postfix({'Train L2': f'{train_l2:.6f}', 'Test L2': f'{test_l2:.6f}'})\n",
    "\n",
    "print(f\"Final train loss: {train_losses_2d[-1]:.6f}\")\n",
    "print(f\"Final test loss: {test_losses_2d[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "q1f8x6eD35Rm",
    "outputId": "c1e06463-970d-488c-d372-f0468e86171b"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_2d, label='Train', alpha=0.8)\n",
    "plt.plot(test_losses_2d, label='Test', alpha=0.8)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Relative L2 Loss')\n",
    "plt.title('FNO2d Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALHoo9B435Rn"
   },
   "source": [
    "### 2D FNO Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8H99PK8O35Rn",
    "outputId": "d08174a0-f506-4250-b944-a796f613939d"
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model_2d.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get predictions for first 4 test samples\n",
    "    x_plot_2d = x_test_2d[:4].to(device)\n",
    "    y_plot_2d = y_test_2d[:4]  # Already in original space (not normalized)\n",
    "    pred_plot_2d = model_2d(x_plot_2d)\n",
    "\n",
    "    # Decode predictions only (y_test_2d was never normalized)\n",
    "    pred_plot_2d = y_normalizer.decode(pred_plot_2d).cpu()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 18))\n",
    "\n",
    "for i in range(4):\n",
    "    # True solution\n",
    "    im1 = axes[i, 0].imshow(y_plot_2d[i], cmap='coolwarm')\n",
    "    axes[i, 0].set_title(f'Test {i+1}: True u(x,y)')\n",
    "    axes[i, 0].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[i, 0])\n",
    "\n",
    "    # Prediction\n",
    "    im2 = axes[i, 1].imshow(pred_plot_2d[i], cmap='coolwarm')\n",
    "    axes[i, 1].set_title(f'Test {i+1}: FNO Prediction')\n",
    "    axes[i, 1].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[i, 1])\n",
    "\n",
    "    # Error\n",
    "    error_map = torch.abs(y_plot_2d[i] - pred_plot_2d[i])\n",
    "    rel_error = torch.norm(pred_plot_2d[i] - y_plot_2d[i]) / torch.norm(y_plot_2d[i])\n",
    "    im3 = axes[i, 2].imshow(error_map, cmap='hot')\n",
    "    axes[i, 2].set_title(f'Test {i+1}: Error (rel={rel_error:.4f})')\n",
    "    axes[i, 2].axis('off')\n",
    "    plt.colorbar(im3, ax=axes[i, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87wt9_kM35Rn"
   },
   "source": [
    "## Key Insights & Analysis\n",
    "\n",
    "### What Makes FNO Special?\n",
    "\n",
    "1. **Mesh Independence**\n",
    "   - Train on one resolution, evaluate on any resolution\n",
    "   - Works because we learn in Fourier space (continuous representation)\n",
    "   - Discretization is only for FFT computation\n",
    "\n",
    "2. **Computational Efficiency**\n",
    "   - FFT: $O(N \\log N)$ vs dense convolution $O(N^2)$\n",
    "   - Once trained: milliseconds per evaluation\n",
    "   - Traditional solver: seconds to minutes\n",
    "\n",
    "3. **Global Receptive Field**\n",
    "   - Fourier modes capture global information\n",
    "   - No need to stack many layers for long-range dependencies\n",
    "   - Contrast with CNNs: local receptive fields\n",
    "\n",
    "4. **Physics-Informed Design**\n",
    "   - Leverages 50+ years of spectral methods knowledge\n",
    "   - Natural for PDEs with periodic boundary conditions\n",
    "   - Low-frequency truncation = implicit regularization\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Periodic Boundary Conditions**\n",
    "   - Standard FFT assumes periodicity\n",
    "   - Extensions needed for general geometries (Geo-FNO)\n",
    "\n",
    "2. **Data Requirements**\n",
    "   - Need many solved PDE instances for training\n",
    "   - Expensive data generation phase\n",
    "\n",
    "3. **Black Box Nature**\n",
    "   - No explicit PDE enforcement during training\n",
    "   - May violate physical constraints\n",
    "\n",
    "### FNO vs DeepONet\n",
    "\n",
    "| Aspect | DeepONet | FNO |\n",
    "|--------|----------|-----|\n",
    "| **Architecture** | Branch-Trunk | Spectral Convolution |\n",
    "| **Space** | Physical | Fourier |\n",
    "| **Queries** | Arbitrary points | Grid points (FFT) |\n",
    "| **Best for** | Irregular domains | Periodic domains |\n",
    "| **Parameters** | More | Fewer |\n",
    "| **Speed** | Fast | Faster (FFT) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6wTxOcR35Rn"
   },
   "source": [
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Conceptual Foundation**\n",
    "   - CNNs are local kernel operators\n",
    "   - FNO extends to global kernel operators in Fourier space\n",
    "   - Physics naturally lives in spectral domain\n",
    "\n",
    "2. **Mathematical Framework**\n",
    "   - Fourier Transform decomposes functions into frequency components\n",
    "   - Convolution theorem: multiplication in Fourier space\n",
    "   - Operator parametrization: $\\mathcal{K}(v) = \\mathcal{F}^{-1}(R_\\phi \\cdot \\mathcal{F}(v))$\n",
    "\n",
    "3. **Architecture**\n",
    "   - Spectral convolution layers: FFT → Learn → IFFT\n",
    "   - Skip connections for expressivity\n",
    "   - Mode truncation for efficiency and regularization\n",
    "\n",
    "4. **Applications**\n",
    "   - 1D Burgers: temporal evolution of shock waves\n",
    "   - 2D Darcy: steady-state flow in porous media\n",
    "   - Mesh-independent predictions\n",
    "\n",
    "### When to Use FNO\n",
    "\n",
    "**Ideal scenarios:**\n",
    "- Periodic or translation-invariant problems\n",
    "- Need for resolution independence\n",
    "- Real-time PDE solving\n",
    "- Large-scale parameter sweeps\n",
    "\n",
    "**Consider alternatives when:**\n",
    "- Complex, non-periodic geometries\n",
    "- Sparse, irregular data\n",
    "- Need point-wise queries at arbitrary locations\n",
    "- Limited training data\n",
    "\n",
    "### Extensions\n",
    "\n",
    "- **Geo-FNO:** Arbitrary geometries with coordinate transforms\n",
    "- **Physics-Informed FNO:** Add PDE residual to loss\n",
    "- **Factorized FNO:** Low-rank approximations for 3D\n",
    "- **U-FNO:** U-Net architecture with Fourier layers\n",
    "\n",
    "---\n",
    "\n",
    "**Further Reading:**\n",
    "- [Original FNO Paper](https://arxiv.org/abs/2010.08895)\n",
    "- [Geo-FNO](https://arxiv.org/abs/2207.05209)\n",
    "- [Physics-Informed Neural Operators](https://arxiv.org/abs/2111.03794)\n",
    "- [Neural Operator Review](https://arxiv.org/abs/2108.08481)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
