{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptrons: From Theory to Classification\n",
    "\n",
    "**Exercise:** [![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-F9AB00?style=flat-square&logo=googlecolab)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/00-mlp/00b-mlp-classification-exercise.ipynb)\n",
    "**Solution:** [![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-F9AB00?style=flat-square&logo=googlecolab)](https://colab.research.google.com/github/kks32-courses/sciml/blob/main/docs/00-mlp/00b-mlp-classification.ipynb)\n",
    "\n",
    "This notebook introduces **Multi-Layer Perceptrons (MLPs)** from fundamental concepts to practical classification applications. We'll build neural networks from scratch, understand their mathematical foundations, and apply them to solve real-world geotechnical engineering problems.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "\n",
    "1. **The Perceptron**: The fundamental building block of neural networks\n",
    "2. **Activation Functions**: Why non-linearity is essential for learning complex patterns\n",
    "3. **MLP Architecture**: How layers combine to create powerful function approximators\n",
    "4. **Automatic Differentiation**: How neural networks compute gradients efficiently\n",
    "5. **Gradient Descent**: The optimization algorithm that trains neural networks\n",
    "6. **Classification**: Applying MLPs to real-world decision-making problems\n",
    "\n",
    "We'll demonstrate these concepts using a practical geotechnical engineering problem: predicting earthquake-induced liquefaction.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Understanding the Building Blocks\n",
    "\n",
    "## What is a Perceptron?\n",
    "\n",
    "The **perceptron** is the fundamental unit of a neural network, inspired by biological neurons. It takes multiple inputs, computes a weighted sum, adds a bias, and passes the result through an activation function.\n",
    "\n",
    "### Mathematical Definition\n",
    "\n",
    "For inputs $\\boldsymbol{x} = [x_1, x_2, ..., x_n]$ and weights $\\boldsymbol{w} = [w_1, w_2, ..., w_n]$:\n",
    "\n",
    "$$z = \\boldsymbol{w}^T\\boldsymbol{x} + b = \\sum_{i=1}^n w_i x_i + b$$\n",
    "\n",
    "$$\\hat{y} = g(z)$$\n",
    "\n",
    "Where:\n",
    "- $z$ is the **pre-activation** (linear combination)\n",
    "- $g(z)$ is the **activation function** (introduces non-linearity)\n",
    "- $b$ is the **bias** (shifts the decision boundary)\n",
    "- $\\hat{y}$ is the **output**\n",
    "\n",
    "### The Key Components\n",
    "\n",
    "1. **Inputs** ($\\boldsymbol{x}$): The features or data we want to process\n",
    "2. **Weights** ($\\boldsymbol{w}$): Learnable parameters that determine feature importance\n",
    "3. **Bias** ($b$): Learnable parameter that shifts the activation threshold\n",
    "4. **Activation Function** ($g$): Non-linear function that enables complex pattern learning\n",
    "\n",
    "![Perceptron Diagram](https://raw.githubusercontent.com/kks32-courses/sciml/main/docs/00-mlp/figs/perceptron.png)\n",
    "\n",
    "### Why Do We Need Multiple Perceptrons?\n",
    "\n",
    "A single perceptron can only learn **linear decision boundaries**. For complex patterns, we need to combine multiple perceptrons into **layers**, creating a **Multi-Layer Perceptron (MLP)**.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: The Critical Role of Activation Functions\n",
    "\n",
    "## Why Non-Linearity Matters\n",
    "\n",
    "**Question**: What happens if we stack multiple linear layers without activation functions?\n",
    "\n",
    "Let the first layer be $h_1 = W_1 x + b_1$ and the second layer be $h_2 = W_2 h_1 + b_2$.\n",
    "\n",
    "Substituting: $h_2 = W_2 (W_1 x + b_1) + b_2 = (W_2 W_1) x + (W_2 b_1 + b_2)$\n",
    "\n",
    "This is just another linear function! **Without activation functions, any number of layers collapses to a single linear transformation.**\n",
    "\n",
    "## Common Activation Functions\n",
    "\n",
    "### 1. Sigmoid Function\n",
    "$$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "\n",
    "- **Range**: (0, 1)\n",
    "- **Properties**: Smooth, differentiable\n",
    "- **Problems**: Vanishing gradients, not zero-centered\n",
    "- **Use**: Output layer for binary classification\n",
    "\n",
    "### 2. Hyperbolic Tangent (Tanh)\n",
    "$$\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$\n",
    "\n",
    "- **Range**: (-1, 1)\n",
    "- **Properties**: Zero-centered, smooth\n",
    "- **Problems**: Still suffers from vanishing gradients\n",
    "- **Use**: Hidden layers (better than sigmoid)\n",
    "\n",
    "### 3. ReLU (Rectified Linear Unit)\n",
    "$$\\text{ReLU}(x) = \\max(0, x)$$\n",
    "\n",
    "- **Range**: [0, ∞)\n",
    "- **Properties**: Simple, computationally efficient\n",
    "- **Advantages**: Addresses vanishing gradient problem\n",
    "- **Problems**: \"Dead neurons\" (always output 0)\n",
    "- **Use**: Most popular for hidden layers\n",
    "\n",
    "### 4. Leaky ReLU\n",
    "$$\\text{LeakyReLU}(x) = \\max(\\alpha x, x)$$ \n",
    "\n",
    "where $\\alpha \\approx 0.01$\n",
    "\n",
    "- **Range**: (-∞, ∞)\n",
    "- **Properties**: Prevents dead neurons\n",
    "- **Use**: Alternative to ReLU when dead neurons are problematic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activation functions to understand their properties\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))  # Clip to prevent overflow\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.maximum(alpha * x, x)\n",
    "\n",
    "# Create input range\n",
    "x = np.linspace(-5, 5, 200)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Common Activation Functions', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Sigmoid\n",
    "axes[0, 0].plot(x, sigmoid(x), 'b-', linewidth=3, label='Sigmoid')\n",
    "axes[0, 0].set_title('Sigmoid: σ(x) = 1/(1+e^-x)', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Output')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].axhline(y=0, color='k', linewidth=0.8)\n",
    "axes[0, 0].axvline(x=0, color='k', linewidth=0.8)\n",
    "axes[0, 0].set_ylim(-0.1, 1.1)\n",
    "\n",
    "# Tanh\n",
    "axes[0, 1].plot(x, tanh(x), 'r-', linewidth=3, label='Tanh')\n",
    "axes[0, 1].set_title('Tanh: tanh(x)', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Output')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].axhline(y=0, color='k', linewidth=0.8)\n",
    "axes[0, 1].axvline(x=0, color='k', linewidth=0.8)\n",
    "axes[0, 1].set_ylim(-1.1, 1.1)\n",
    "\n",
    "# ReLU\n",
    "axes[1, 0].plot(x, relu(x), 'g-', linewidth=3, label='ReLU')\n",
    "axes[1, 0].set_title('ReLU: max(0, x)', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Input')\n",
    "axes[1, 0].set_ylabel('Output')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].axhline(y=0, color='k', linewidth=0.8)\n",
    "axes[1, 0].axvline(x=0, color='k', linewidth=0.8)\n",
    "axes[1, 0].set_ylim(-0.5, 5)\n",
    "\n",
    "# Leaky ReLU\n",
    "axes[1, 1].plot(x, leaky_relu(x), 'm-', linewidth=3, label='Leaky ReLU')\n",
    "axes[1, 1].set_title('Leaky ReLU: max(0.01x, x)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Input')\n",
    "axes[1, 1].set_ylabel('Output')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].axhline(y=0, color='k', linewidth=0.8)\n",
    "axes[1, 1].axvline(x=0, color='k', linewidth=0.8)\n",
    "axes[1, 1].set_ylim(-0.5, 5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Properties:\")\n",
    "print(\"• Sigmoid: Smooth, bounded (0,1), but saturates → vanishing gradients\")\n",
    "print(\"• Tanh: Zero-centered, bounded (-1,1), still saturates\")\n",
    "print(\"• ReLU: Simple, no saturation for x>0, but 'dies' for x<0\")\n",
    "print(\"• Leaky ReLU: Prevents dead neurons, slight negative slope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Demo: Visualizing Nonlinear Transformation\n",
    "\n",
    "This interactive demo illustrates how a combination of linear transformation and non-linearity can transform data in a way that linear transformations alone cannot. Observe how the data, initially not linearly separable in the input space (X), becomes separable after passing through a linear layer (Y) and then a non-linear activation (Z).\n",
    "\n",
    "This provides intuition for why layers with non-linear activations are powerful: they can map data into a new space where complex patterns become simpler (potentially linearly separable), making them learnable by subsequent layers.\n",
    "\n",
    "[![Button](https://img.shields.io/badge/Go%20to-Interactive%20Demo:ReLU-blue?style=for-the-badge)](../relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Multi-Layer Perceptron Architecture\n",
    "\n",
    "## From Single Perceptron to MLP\n",
    "\n",
    "A **Multi-Layer Perceptron (MLP)** consists of multiple layers of perceptrons:\n",
    "\n",
    "1. **Input Layer**: Receives the raw features\n",
    "2. **Hidden Layer(s)**: Perform non-linear transformations\n",
    "3. **Output Layer**: Produces the final prediction\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "For a two-layer MLP:\n",
    "\n",
    "**Hidden Layer:**\n",
    "$$\\boldsymbol{h} = g_1(W^{(1)}\\boldsymbol{x} + \\boldsymbol{b}^{(1)})$$\n",
    "\n",
    "**Output Layer:**\n",
    "$$\\hat{\\boldsymbol{y}} = g_2(W^{(2)}\\boldsymbol{h} + \\boldsymbol{b}^{(2)})$$\n",
    "\n",
    "Where:\n",
    "- $W^{(1)}, \\boldsymbol{b}^{(1)}$: Weights and biases of the hidden layer\n",
    "- $W^{(2)}, \\boldsymbol{b}^{(2)}$: Weights and biases of the output layer\n",
    "- $g_1, g_2$: Activation functions for hidden and output layers\n",
    "\n",
    "### Key Architecture Decisions\n",
    "\n",
    "1. **Number of Hidden Layers (Depth)**\n",
    "   - More layers → more complex patterns\n",
    "   - But also → harder to train, more parameters\n",
    "\n",
    "2. **Number of Neurons per Layer (Width)**\n",
    "   - More neurons → higher capacity\n",
    "   - But also → more overfitting risk\n",
    "\n",
    "3. **Activation Functions**\n",
    "   - Hidden layers: ReLU (most common), Tanh, etc.\n",
    "   - Output layer: Depends on task (Sigmoid for binary, Softmax for multi-class)\n",
    "\n",
    "4. **Universal Approximation Theorem**\n",
    "   - Single hidden layer with enough neurons can approximate any continuous function\n",
    "   - But may require exponentially many neurons!\n",
    "   - Deep networks are often more parameter-efficient\n",
    "\n",
    "![MLP Architecture](https://raw.githubusercontent.com/kks32-courses/sciml/main/docs/00-mlp/figs/single-layer-nn2.png)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Automatic Differentiation - The Engine of Deep Learning\n",
    "\n",
    "## Why Do We Need Gradients?\n",
    "\n",
    "To train a neural network, we need to adjust the parameters (weights and biases) to minimize a loss function. This requires computing **gradients** - the partial derivatives of the loss with respect to each parameter.\n",
    "\n",
    "For a simple function $f(x) = x^2$, the gradient is $\\frac{df}{dx} = 2x$. But neural networks have millions of parameters and complex computational graphs!\n",
    "\n",
    "## The Computational Graph Perspective\n",
    "\n",
    "Every function can be decomposed into elementary operations. Consider:\n",
    "$$f(x_1, x_2) = x_1^2 + x_2$$\n",
    "\n",
    "This creates a computational graph:\n",
    "- $v_1 = x_1^2$ (square operation)\n",
    "- $f = v_1 + x_2$ (addition operation)\n",
    "\n",
    "## Forward Mode vs Reverse Mode AD\n",
    "\n",
    "### Forward Mode\n",
    "- Propagates derivatives **forward** through the graph\n",
    "- Efficient when: few inputs, many outputs\n",
    "- Computes one gradient at a time\n",
    "\n",
    "### Reverse Mode (Backpropagation)\n",
    "- Propagates derivatives **backward** through the graph\n",
    "- Efficient when: many inputs, few outputs (neural networks!)\n",
    "- Computes all gradients in one pass\n",
    "\n",
    "## The Chain Rule: Foundation of Backpropagation\n",
    "\n",
    "For composite functions $f(g(x))$:\n",
    "$$\\frac{df}{dx} = \\frac{df}{dg} \\cdot \\frac{dg}{dx}$$\n",
    "\n",
    "In neural networks:\n",
    "$$\\frac{\\partial L}{\\partial W^{(1)}} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial h} \\cdot \\frac{\\partial h}{\\partial W^{(1)}}$$\n",
    "\n",
    "Where $L$ is loss, $\\hat{y}$ is output, $h$ is hidden layer, and $W^{(1)}$ are input-to-hidden weights.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate automatic differentiation in PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"=== Automatic Differentiation Demo ===\")\n",
    "\n",
    "# Simple function: f(x1, x2) = x1^2 + x2\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "y = x1**2 + x2\n",
    "print(f\"f({x1.item()}, {x2.item()}) = {y.item()}\")\n",
    "\n",
    "# Backward pass (compute gradients)\n",
    "y.backward()\n",
    "\n",
    "print(f\"∂f/∂x1 = {x1.grad.item():.1f} (analytical: 2*x1 = {2*x1.item():.1f})\")\n",
    "print(f\"∂f/∂x2 = {x2.grad.item():.1f} (analytical: 1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 =      # 2 inputs → 3 hidden\n",
    "        self.layer2 =      # 3 hidden → 1 output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.layer1(x))\n",
    "        return torch.sigmoid(self.layer2(h))\n",
    "\n",
    "# Create network and input\n",
    "net = SimpleNet()\n",
    "x = torch.tensor([[1.0, 2.0]])  # Batch of 1 sample\n",
    "y_true = torch.tensor([[1.0]])  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "y_pred = \n",
    "loss = \n",
    "\n",
    "print(f\"Prediction: {y_pred.item():.4f}\")\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Backward pass\n",
    "\n",
    "\n",
    "# Display gradients\n",
    "print(\"\\nGradients computed automatically:\")\n",
    "for name, param in net.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        print(f\"{name}: shape {param.grad.shape}, mean grad = {param.grad.mean().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a neural network\n",
    "\n",
    "Neural networks are trained using an optimization algorithm that iteratively updates the network's weights and biases to minimize a loss function. The loss function measures how far the network's predictions are from the true target outputs in the training data. It is a measure of the model's error.\n",
    "\n",
    "We quantify this difference using a **Loss Function**. Some common loss functions include:\n",
    "\n",
    "* **Mean squared error (MSE)** - The average of the squared differences between the predicted and actual values. Measures the square of the error. Used for regression problems.\n",
    "\n",
    "* **Cross-entropy loss** - Measures the divergence between the predicted class probabilities and the true distribution. Used for classification problems. Penalizes confident incorrect predictions.\n",
    "\n",
    "* **Hinge loss** - Used for Support Vector Machines classifiers. Penalizes predictions that are on the wrong side of the decision boundary.\n",
    "\n",
    "For our **binary classification** task (liquefaction prediction), the **Binary Cross-Entropy Loss** is the optimal choice:\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = -\\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right]$$\n",
    "\n",
    "where:\n",
    "- $y_i \\in \\{0, 1\\}$ is the true class label (0 = No Liquefaction, 1 = Liquefaction)\n",
    "- $\\hat{y}_i \\in (0, 1)$ is the predicted probability from the sigmoid output\n",
    "- $N$ is the number of training samples\n",
    "\n",
    "**Why Cross-Entropy for Classification?**\n",
    "\n",
    "1. **Probabilistic Interpretation**: Maximizes the likelihood of the correct class\n",
    "2. **Stronger Gradients**: Provides larger gradients for incorrect confident predictions\n",
    "3. **Numerical Stability**: Works well with sigmoid activation functions\n",
    "4. **Convex Loss Surface**: Easier optimization compared to other classification losses\n",
    "\n",
    "**Mathematical Intuition**:\n",
    "- When $y_i = 1$ (liquefaction occurs): Loss = $-\\log(\\hat{y}_i)$\n",
    "  - If $\\hat{y}_i \\approx 1$ (correct confident prediction): Loss ≈ 0\n",
    "  - If $\\hat{y}_i \\approx 0$ (wrong confident prediction): Loss → ∞\n",
    "- When $y_i = 0$ (no liquefaction): Loss = $-\\log(1-\\hat{y}_i)$  \n",
    "  - If $\\hat{y}_i \\approx 0$ (correct confident prediction): Loss ≈ 0\n",
    "  - If $\\hat{y}_i \\approx 1$ (wrong confident prediction): Loss → ∞\n",
    "\n",
    "Minimizing this loss function with respect to the parameters $\\theta$ is an optimization problem.\n",
    "\n",
    "Loss optimization is the process of finding the network weights that achieve the lowest loss.\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\boldsymbol{w^*} &= \\argmin_{\\boldsymbol{w}}\\frac{1}{n}\\sum_{i=1}^n \\mathcal{L}(f(x^{(i)};\\boldsymbol{w}),y^{(i)})\\\\\n",
    "\\boldsymbol{w^*} &= \\argmin_{\\boldsymbol{w}} J(\\boldsymbol{w})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The training process works like this:\n",
    "\n",
    "1. **Initialization**: The weights and biases of the network are initialized, often with small random numbers.\n",
    "\n",
    "2. **Forward Pass**: The input is passed through the network, layer by layer, applying the necessary transformations (e.g., linear combinations of weights and inputs followed by activation functions) until an output is obtained.\n",
    "\n",
    "3. **Calculate Loss**: The binary cross-entropy loss function is used to quantify the difference between the predicted probabilities and the actual target class labels.\n",
    "\n",
    "4. **Backward Pass (Backpropagation)**: The gradients of the loss with respect to the parameters (weights and biases) are computed using the chain rule for derivatives. This process is known as backpropagation.\n",
    "\n",
    "5. **Update Parameters**: The gradients computed in the backward pass are used to update the parameters of the network, typically using optimization algorithms like stochastic gradient descent (SGD) or more sophisticated ones like Adam. The update is done in the direction that minimizes the loss.\n",
    "\n",
    "6. **Repeat**: Steps 2-5 are repeated using the next batch of data until a stopping criterion is met, such as a set number of epochs (full passes through the training dataset) or convergence to a minimum loss value.\n",
    "\n",
    "7. **Validation**: The model is evaluated on a separate validation set to assess its generalization to unseen data.\n",
    "\n",
    "The goal of training is to find the optimal set of weights and biases $\\theta^*$ for the network that minimize the binary cross-entropy loss between the network's probability output $\\hat{y}_{NN}(x; \\theta)$ and the true training labels $y_{train}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing gradients with Automatic Differentiation\n",
    "\n",
    "> The Core Insight: Functions Are Computational Graphs\n",
    "\n",
    "Every computer program that evaluates a mathematical function can be viewed as a **computational graph**. Consider this simple function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Button](https://img.shields.io/badge/Go%20to-Interactive%20Demo-blue?style=for-the-badge&logo=airplayvideo&logoColor=white)](../ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1, x2):\n",
    "    y = x1**2 + x2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a computational graph where each operation is a node. This decomposition is the key insight that makes automatic differentiation possible.\n",
    "\n",
    "![AD forward pass](figs/ad3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Mode Automatic Differentiation\n",
    "\n",
    "Reverse mode AD (also called **backpropagation**) computes derivatives by propagating derivative information **backward** through the computational graph.\n",
    "\n",
    "### The Backward Pass Algorithm\n",
    "\n",
    "1. **Forward pass**: Compute function values and store intermediate results\n",
    "2. **Seed the output**: Set $\\bar{y} = 1$ (derivative of output w.r.t. itself)\n",
    "3. **Backward pass**: Use the chain rule to propagate derivatives backward\n",
    "\n",
    "![Final chain rule AD](figs/ad7.png)\n",
    "\n",
    "### Computing All Partial Derivatives in One Pass\n",
    "\n",
    "The beauty of reverse mode is that it computes **all** partial derivatives in a single backward pass:\n",
    "\n",
    "1. **Forward pass**: $y = x_1^2 + x_2$ (store intermediate values)\n",
    "\n",
    "2. **Backward pass with $\\bar{y} = 1$**:\n",
    "   - $\\frac{\\partial y}{\\partial x_1} = \\frac{\\partial y}{\\partial v_1} \\cdot \\frac{\\partial v_1}{\\partial x_1} = 1 \\cdot 2x_1 = 2x_1$\n",
    "   - $\\frac{\\partial y}{\\partial x_2} = \\frac{\\partial y}{\\partial x_2} = 1$\n",
    "\n",
    "**Key insight**: Reverse mode computes gradients w.r.t. all inputs in a single backward pass!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AD: The Mathematical Foundation\n",
    "\n",
    "Automatic differentiation works because of a fundamental theorem:\n",
    "\n",
    "**Chain Rule**: For composite functions $f(g(x))$:\n",
    "$$\\frac{d}{dx}f(g(x)) = f'(g(x)) \\cdot g'(x)$$\n",
    "\n",
    "By systematically applying the chain rule to each operation in a computational graph, AD can compute exact derivatives for arbitrarily complex functions.\n",
    "\n",
    "### Automatic Differentiation in Practice: PyTorch\n",
    "\n",
    "Let's see how automatic differentiation works in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define variables that require gradients\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Define the function\n",
    "y = x1**2 + x2\n",
    "\n",
    "# Compute gradients using reverse mode AD\n",
    "y.backward()\n",
    "\n",
    "# Access the computed gradients\n",
    "print(f\"dy/dx1: {x1.grad.item()}\")  # Should be 2*x1 = 4.0\n",
    "print(f\"dy/dx2: {x2.grad.item()}\")  # Should be 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Gradient Descent\n",
    "Gradient Descent is a first-order iterative optimization algorithm used to find the minimum of a differentiable function. In the context of training a neural network, we are trying to minimize the loss function. \n",
    "\n",
    "1. **Initialize Parameters**:\n",
    "\n",
    "Choose an initial point (i.e., initial values for the weights and biases) in the parameter space, and set a learning rate that determines the step size in each iteration.\n",
    "\n",
    "2. **Compute the Gradient**:\n",
    "\n",
    "Calculate the gradient of the loss function with respect to the parameters at the current point. The gradient is a vector that points in the direction of the steepest increase of the function. It is obtained by taking the partial derivatives of the loss function with respect to each parameter.\n",
    "\n",
    "3. **Update Parameters**:\n",
    "\n",
    "Move in the opposite direction of the gradient by a distance proportional to the learning rate. This is done by subtracting the gradient times the learning rate from the current parameters:\n",
    "\n",
    "$$\\boldsymbol{w} = \\boldsymbol{w} - \\eta \\nabla J(\\boldsymbol{w})$$\n",
    "\n",
    "Here, $\\boldsymbol{w}$ represents the parameters, $\\eta$ is the learning rate, and $\\nabla J (\\boldsymbol{w})$ is the gradient of the loss function $J$ with respect to $\\boldsymbol{w}$.\n",
    "\n",
    "4. **Repeat**:\n",
    "\n",
    "Repeat steps 2 and 3 until the change in the loss function falls below a predefined threshold, or a maximum number of iterations is reached.\n",
    "\n",
    "#### Algorithm:\n",
    "\n",
    "1. Initialize weights randomly $\\sim \\mathcal{N}(0, \\sigma^2)$\n",
    "2. Loop until convergence\n",
    "3.   Compute gradient, $\\frac{\\partial J(\\boldsymbol{w})}{\\partial \\boldsymbol{w}}$\n",
    "4.   Update weights, $\\boldsymbol{w} \\leftarrow \\boldsymbol{w} - \\eta \\frac{\\partial J(\\boldsymbol{w})}{\\partial \\boldsymbol{w}}$\n",
    "5. Return weights\n",
    "\n",
    "![SGD](figs/sgd.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming a loss function is mean squared error (MSE). Let's compute the gradient of the loss with respect to the input weights. \n",
    "\n",
    "The loss function is mean squared error:\n",
    "\n",
    "$$\\text{loss} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Where $y_i$ are the true target and $\\hat{y}_i$ are the predicted values.\n",
    "\n",
    "To minimize this loss, we need to compute the gradients with respect to the weights $\\mathbf{w}$ and bias $b$:\n",
    "\n",
    "Using the chain rule, the gradient of the loss with respect to the weights is:\n",
    "$$\\frac{\\partial \\text{loss}}{\\partial \\mathbf{w}} = \\frac{2}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i) \\frac{\\partial y_i}{\\partial \\mathbf{w}}$$\n",
    "\n",
    "The term inside the sum is the gradient of the loss with respect to the output $y_i$, which we called $\\text{grad\\_output}$:\n",
    "$$\\text{grad\\_output} = \\frac{2}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)$$\n",
    "\n",
    "The derivative $\\frac{\\partial y_i}{\\partial \\mathbf{w}}$ is just the input $\\mathbf{x}_i$ multiplied by the derivative of the activation. For simplicity, let's assume linear activation, so this is just $\\mathbf{x}_i$:\n",
    "\n",
    "$$\\therefore \\frac{\\partial \\text{loss}}{\\partial \\mathbf{w}} = \\mathbf{X}^T\\text{grad\\_output}$$\n",
    "\n",
    "The gradient for the bias is simpler:\n",
    "$$\\frac{\\partial \\text{loss}}{\\partial b} = \\sum_{i=1}^{n}\\text{grad\\_output}_i$$\n",
    "\n",
    "Finally, we update the weights and bias by gradient descent:\n",
    "\n",
    "$$\\mathbf{w} = \\mathbf{w} - \\eta \\frac{\\partial \\text{loss}}{\\partial \\mathbf{w}}$$\n",
    "\n",
    "$$b = b - \\eta \\frac{\\partial \\text{loss}}{\\partial b}$$\n",
    "\n",
    "Where $\\eta$ is the learning rate.\n",
    "\n",
    "#### Variants:\n",
    "\n",
    "There are several variants of Gradient Descent that modify or enhance these basic steps, including:\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD)**: Instead of using the entire dataset to compute the gradient, SGD uses a single random data point (or small batch) at each iteration. This adds noise to the gradient but often speeds up convergence and can escape local minima.\n",
    "\n",
    "- **Momentum**: Momentum methods use a moving average of past gradients to dampen oscillations and accelerate convergence, especially in cases where the loss surface has steep valleys.\n",
    "\n",
    "- **Adaptive Learning Rate Methods**: Techniques like Adagrad, RMSprop, and Adam adjust the learning rate individually for each parameter, often leading to faster convergence.\n",
    "\n",
    "#### Limitations:\n",
    "\n",
    "* It may converge to a local minimum instead of a global minimum if the loss surface is not convex.\n",
    "* Convergence can be slow if the learning rate is not properly tuned.\n",
    "* Sensitive to the scaling of features; poorly scaled data can cause the gradient descent to take a long time to converge or even diverge.\n",
    "\n",
    "#### Effect of learning rate\n",
    "\n",
    "The learning rate in gradient descent is a critical hyperparameter that can significantly influence the model's training dynamics. Let us now look at how the learning rate affects local minima, overshooting, and convergence:\n",
    "\n",
    "1. Effect on Local Minima:\n",
    "\n",
    "- High Learning Rate: A large learning rate can help the model escape shallow local minima, leading to the discovery of deeper (potentially global) minima. However, it can also cause instability, making it hard to settle in a good solution.\n",
    "\n",
    "- Low Learning Rate: A small learning rate may cause the model to get stuck in local minima, especially in complex loss landscapes with many shallow valleys. The model can lack the \"energy\" to escape these regions.\n",
    "\n",
    "2. Effect on Overshooting:\n",
    "\n",
    "- High Learning Rate: If the learning rate is set too high, the updates may be so large that they overshoot the minimum and cause the algorithm to diverge, or oscillate back and forth across the valley without ever reaching the bottom. This oscillation can be detrimental to convergence.\n",
    "   \n",
    "- Low Learning Rate: A very low learning rate will likely avoid overshooting but may lead to extremely slow convergence, as the updates to the parameters will be minimal. It might result in getting stuck in plateau regions where the gradient is small.\n",
    "\n",
    "3. Effect on Convergence:\n",
    "\n",
    "- High Learning Rate: While it can speed up convergence initially, a too-large learning rate risks instability and divergence, as mentioned above. The model may never converge to a satisfactory solution.\n",
    "   \n",
    "- Low Learning Rate: A small learning rate ensures more stable and reliable convergence but can significantly slow down the process. If set too low, it may also lead to premature convergence to a suboptimal solution.\n",
    "\n",
    "##### Finding the Right Balance:\n",
    "\n",
    "Choosing the right learning rate is often a trial-and-error process, sometimes guided by techniques like learning rate schedules or adaptive learning rate algorithms like Adam. These approaches attempt to balance the trade-offs by adjusting the learning rate throughout training, often starting with larger values to escape local minima and avoid plateaus, then reducing it to stabilize convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Button](https://img.shields.io/badge/Go%20to-Interactive%20Demo:SGD-blue?style=for-the-badge&logo=airplayvideo&logoColor=white)](../sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Real-World Application - Earthquake Liquefaction Prediction\n",
    "\n",
    "## The Engineering Problem\n",
    "\n",
    "**Soil liquefaction** occurs when saturated loose sandy soils lose strength during earthquakes, causing:\n",
    "- Building foundations to sink or tilt\n",
    "- Underground pipes to float to the surface  \n",
    "- Lateral spreading of ground causing infrastructure damage\n",
    "\n",
    "**Our Goal**: Predict which sites will experience lateral spreading (> 0.3m displacement) based on:\n",
    "\n",
    "### Input Features\n",
    "1. **GWD (Ground Water Depth, m)**: Deeper water table → lower liquefaction risk\n",
    "2. **L (Distance to river, km)**: Closer to water bodies → higher risk  \n",
    "3. **Slope (%)**: Steeper slopes → more lateral spreading potential\n",
    "4. **PGA (Peak Ground Acceleration, g)**: Higher shaking intensity → more damage\n",
    "\n",
    "### Target Variable\n",
    "- **Binary classification**: 0 = No liquefaction, 1 = Liquefaction occurs\n",
    "\n",
    "This is a perfect problem for MLPs because:\n",
    "- **Non-linear relationships**: Liquefaction risk isn't simply additive\n",
    "- **Feature interactions**: GWD and PGA interact in complex ways\n",
    "- **Engineering significance**: Wrong predictions can mean lives and property lost\n",
    "\n",
    "### Why MLPs vs Traditional Methods?\n",
    "\n",
    "**Traditional approach**: Linear models or simple rules\n",
    "- Example: \"If GWD < 2m AND PGA > 0.3g, then liquefaction occurs\"\n",
    "- **Problem**: Real soil behavior is much more complex!\n",
    "\n",
    "**MLP approach**: Learn complex non-linear patterns from data\n",
    "- Can capture interactions between all variables\n",
    "- Adapts to patterns in the specific geological region\n",
    "- Provides probability estimates for risk assessment\n",
    "\n",
    "Let's see how MLPs can outperform traditional methods on this critical engineering problem.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn pandas torch matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Try importing sklearn, install if not available\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'scikit-learn'])\n",
    "    \n",
    "    # Import again after installation\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Plotting setup\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'figure.figsize': (12, 8),\n",
    "    'lines.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Let's load the liquefaction dataset and understand its characteristics:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the liquefaction dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/kks32-courses/sciml/main/lectures/01-classification/RF_YN_Model3.csv')\n",
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the liquefaction dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/kks32-courses/sciml/main/lectures/01-classification/RF_YN_Model3.csv')\n",
    "\n",
    "print(\"=== Dataset Overview ===\")\n",
    "print(f\"Shape: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "print(f\"\\nFeatures: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\n=== Target Distribution ===\")\n",
    "target_counts = df['Target'].value_counts()\n",
    "print(f\"No Liquefaction (0): {target_counts[0]} samples ({target_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Liquefaction (1): {target_counts[1]} samples ({target_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize feature distributions by class\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "features = ['GWD (m)', 'L (km)', 'Slope (%)', 'PGA (g)']\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i//2, i%2]\n",
    "    \n",
    "    # Plot histograms for each class\n",
    "    no_liq = df[df['Target'] == 0][feature]\n",
    "    liq = df[df['Target'] == 1][feature]\n",
    "    \n",
    "    ax.hist(no_liq, bins=30, alpha=0.7, label='No Liquefaction', color='blue', density=True)\n",
    "    ax.hist(liq, bins=30, alpha=0.7, label='Liquefaction', color='red', density=True)\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'Distribution of {feature}', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing for MLP classification\n",
    "# Clean the data and prepare features and target\n",
    "df_clean = df.drop(['Test ID', 'Elevation'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X_data = df_clean.drop(['Target'], axis=1)  # Use different variable name to avoid conflicts\n",
    "y_data = df_clean['Target']  # Use different variable name to avoid conflicts\n",
    "\n",
    "print(\"Features:\")\n",
    "print(X_data.columns.tolist())\n",
    "print(f\"\\\\nTarget distribution:\")\n",
    "print(y_data.value_counts())\n",
    "print(f\"\\\\nClass balance: {y_data.mean():.3f} (fraction of positive cases)\")\n",
    "print(f\"\\\\nFeature shapes: X_data: {X_data.shape}, y_data: {y_data.shape}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\\\nFeature Statistics:\")\n",
    "print(X_data.describe())\n",
    "\n",
    "# Now split the data properly\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=SEED, stratify=y_data\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=SEED, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"\\\\nData splits:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Feature scaling (important for neural networks)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "print(f\"\\\\nTensor shapes:\")\n",
    "print(f\"X_train_tensor: {X_train_tensor.shape}\")\n",
    "print(f\"y_train_tensor: {y_train_tensor.shape}\")\n",
    "print(\"\\\\nData preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VII: Building Our MLP Classifier\n",
    "\n",
    "## Architecture Design for Liquefaction Prediction\n",
    "\n",
    "Our MLP will transform 4 input features into a binary classification decision:\n",
    "\n",
    "**Input Layer**: 4 neurons (GWD, L, Slope, PGA)\n",
    "↓\n",
    "**Hidden Layer 1**: 64 neurons with ReLU activation  \n",
    "↓\n",
    "**Hidden Layer 2**: 32 neurons with ReLU activation\n",
    "↓\n",
    "**Output Layer**: 1 neuron with Sigmoid activation (probability)\n",
    "\n",
    "### Key Design Decisions\n",
    "\n",
    "1. **Hidden Layer Sizes**: 64 → 32 (funnel architecture)\n",
    "   - Start wide to capture complex patterns\n",
    "   - Narrow down to focus on most important features\n",
    "\n",
    "2. **ReLU Activations**: Prevent vanishing gradients, enable deep learning\n",
    "\n",
    "3. **Dropout Regularization**: Prevent overfitting by randomly \"turning off\" neurons\n",
    "\n",
    "4. **Sigmoid Output**: Maps to probability [0,1] for binary classification\n",
    "\n",
    "5. **Binary Cross-Entropy Loss**: Optimal for binary classification problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP Classifier\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_sizes=[64, 32], dropout_rate=0.2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        \n",
    "        # Build the network layers\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer (no activation, we'll add sigmoid separately)\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        layers.append(nn.Sigmoid())  # For binary classification\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Return probabilities\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.forward(x)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Return binary predictions\"\"\"\n",
    "        proba = self.predict_proba(x)\n",
    "        return (proba >= 0.5).float()\n",
    "\n",
    "# Create model instance\n",
    "model = MLPClassifier(input_size=4, hidden_sizes=[64, 32], dropout_rate=0.2)\n",
    "\n",
    "print(\"MLPClassifier defined successfully!\")\n",
    "print(f\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Data preprocessing for MLP classification\n",
    "# Clean the data and prepare features and target\n",
    "df_clean = df.drop(['Test ID', 'Elevation'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X_data = df_clean.drop(['Target'], axis=1)  # Use different variable name to avoid conflicts\n",
    "y_data = df_clean['Target']  # Use different variable name to avoid conflicts\n",
    "\n",
    "print(\"\\\\nFeatures:\")\n",
    "print(X_data.columns.tolist())\n",
    "print(f\"\\\\nTarget distribution:\")\n",
    "print(y_data.value_counts())\n",
    "print(f\"\\\\nClass balance: {y_data.mean():.3f} (fraction of positive cases)\")\n",
    "print(f\"\\\\nFeature shapes: X_data: {X_data.shape}, y_data: {y_data.shape}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\\\nFeature Statistics:\")\n",
    "print(X_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data splitting has been moved to cell-13 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_classifier(model, X_train, y_train, X_val, y_val, \n",
    "                        epochs=1000, lr=0.001, patience=50, verbose=True):\n",
    "    \"\"\"Train MLP classifier with early stopping\"\"\"\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_predictions = model(X_train)\n",
    "        train_loss = criterion(train_predictions, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        train_pred_binary = (train_predictions >= 0.5).float()\n",
    "        train_acc = (train_pred_binary == y_train).float().mean()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_predictions = model(X_val)\n",
    "            val_loss = criterion(val_predictions, y_val)\n",
    "            \n",
    "            val_pred_binary = (val_predictions >= 0.5).float()\n",
    "            val_acc = (val_pred_binary == y_val).float().mean()\n",
    "        \n",
    "        # Store history\n",
    "        history['train_loss'].append(train_loss.item())\n",
    "        history['val_loss'].append(val_loss.item())\n",
    "        history['train_acc'].append(train_acc.item())\n",
    "        history['val_acc'].append(val_acc.item())\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        # Print progress\n",
    "        if verbose and (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]:')\n",
    "            print(f'  Train Loss: {train_loss.item():.4f}, Train Acc: {train_acc:.4f}')\n",
    "            print(f'  Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}')\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "print(\"Training MLP Classifier...\")\n",
    "history = train_mlp_classifier(model, X_train_tensor, y_train_tensor, \n",
    "                              X_val_tensor, y_val_tensor, \n",
    "                              epochs=1000, lr=0.001, patience=50)\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Loss curves\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "ax1.plot(epochs_range, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "ax1.plot(epochs_range, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Binary Cross-Entropy Loss')\n",
    "ax1.set_title('Training and Validation Loss', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(epochs_range, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "ax2.plot(epochs_range, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final performance\n",
    "final_train_acc = history['train_acc'][-1]\n",
    "final_val_acc = history['val_acc'][-1]\n",
    "final_train_loss = history['train_loss'][-1]\n",
    "final_val_loss = history['val_loss'][-1]\n",
    "\n",
    "print(f\"Final Training Performance:\")\n",
    "print(f\"  Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"  Loss: {final_train_loss:.4f}\")\n",
    "print(f\"\\nFinal Validation Performance:\")\n",
    "print(f\"  Accuracy: {final_val_acc:.4f}\")\n",
    "print(f\"  Loss: {final_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get probabilities and predictions\n",
    "    test_proba = model.predict_proba(X_test_tensor).numpy().flatten()\n",
    "    test_pred = model.predict(X_test_tensor).numpy().flatten()\n",
    "    \n",
    "    # Calculate test loss\n",
    "    criterion = nn.BCELoss()\n",
    "    test_loss = criterion(model(X_test_tensor), y_test_tensor)\n",
    "\n",
    "# Test accuracy\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f\"Test Set Performance:\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Loss: {test_loss.item():.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, test_pred, target_names=['No Liquefaction', 'Liquefaction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mlp_feature_importance(model, X, y, feature_names, n_repeats=10):\n",
    "    \"\"\"Calculate feature importance using permutation method\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Baseline accuracy\n",
    "    with torch.no_grad():\n",
    "        baseline_pred = model.predict(X)\n",
    "        baseline_acc = (baseline_pred.flatten() == y.flatten()).float().mean().item()\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        feature_importances = []\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            # Create a copy of the data\n",
    "            X_permuted = X.clone()\n",
    "            \n",
    "            # Permute the i-th feature\n",
    "            perm_idx = torch.randperm(X_permuted.shape[0])\n",
    "            X_permuted[:, i] = X_permuted[perm_idx, i]\n",
    "            \n",
    "            # Calculate accuracy with permuted feature\n",
    "            with torch.no_grad():\n",
    "                permuted_pred = model.predict(X_permuted)\n",
    "                permuted_acc = (permuted_pred.flatten() == y.flatten()).float().mean().item()\n",
    "            \n",
    "            # Importance = decrease in accuracy\n",
    "            importance = baseline_acc - permuted_acc\n",
    "            feature_importances.append(importance)\n",
    "        \n",
    "        importances.append(np.mean(feature_importances))\n",
    "    \n",
    "    return np.array(importances)\n",
    "\n",
    "# Calculate feature importance for MLP\n",
    "feature_names = X_data.columns.tolist()  # Use X_data instead of X\n",
    "mlp_importances = calculate_mlp_feature_importance(model, X_test_tensor, y_test_tensor, feature_names)\n",
    "\n",
    "# Get decision tree feature importance for comparison\n",
    "dt_importances = dt_model.feature_importances_\n",
    "\n",
    "# Create comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# MLP feature importance\n",
    "indices = np.argsort(mlp_importances)[::-1]\n",
    "ax1.bar(range(len(mlp_importances)), mlp_importances[indices], color='blue', alpha=0.7)\n",
    "ax1.set_title('MLP Feature Importance \\n(Permutation Method)', fontweight='bold')\n",
    "ax1.set_xticks(range(len(feature_names)))\n",
    "ax1.set_xticklabels([feature_names[i] for i in indices], rotation=45)\n",
    "ax1.set_ylabel('Importance Score')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Decision tree feature importance\n",
    "indices_dt = np.argsort(dt_importances)[::-1]\n",
    "ax2.bar(range(len(dt_importances)), dt_importances[indices_dt], color='red', alpha=0.7)\n",
    "ax2.set_title('Decision Tree Feature Importance \\n(Gini Impurity)', fontweight='bold')\n",
    "ax2.set_xticks(range(len(feature_names)))\n",
    "ax2.set_xticklabels([feature_names[i] for i in indices_dt], rotation=45)\n",
    "ax2.set_ylabel('Importance Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance rankings\n",
    "print(\"Feature Importance Rankings:\")\n",
    "print(\"\\\\nMLP (Permutation):\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"  {i+1}. {feature_names[idx]}: {mlp_importances[idx]:.4f}\")\n",
    "\n",
    "print(\"\\\\nDecision Tree (Gini):\")\n",
    "for i, idx in enumerate(indices_dt):\n",
    "    print(f\"  {i+1}. {feature_names[idx]}: {dt_importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train decision tree (same parameters as original notebook)\n",
    "dt_model = DecisionTreeClassifier(max_depth=7, random_state=SEED)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "dt_proba = dt_model.predict_proba(X_test)[:, 1]\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "print(f\"Performance Comparison:\")\n",
    "print(f\"  MLP Accuracy:          {test_acc:.4f}\")\n",
    "print(f\"  Decision Tree Accuracy: {dt_acc:.4f}\")\n",
    "print(f\"  Improvement:           {((test_acc - dt_acc) / dt_acc * 100):+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: From Theory to Practice\n",
    "\n",
    "### What We've Accomplished\n",
    "\n",
    "In this comprehensive introduction to MLPs, we've covered:\n",
    "\n",
    "#### 🧠 **Theoretical Foundations**\n",
    "1. **Perceptron Basics**: The fundamental building block of neural networks\n",
    "2. **Activation Functions**: Why ReLU, Sigmoid, and Tanh matter for different tasks\n",
    "3. **MLP Architecture**: How layers combine to create powerful function approximators\n",
    "4. **Universal Approximation Theorem**: The theoretical guarantee that MLPs can learn any function\n",
    "\n",
    "#### ⚙️ **Mathematical Machinery**\n",
    "1. **Automatic Differentiation**: How PyTorch computes gradients through computational graphs\n",
    "2. **Chain Rule**: The mathematical foundation of backpropagation\n",
    "3. **Gradient Descent**: The optimization algorithm that makes learning possible\n",
    "4. **Loss Functions**: Why cross-entropy works better than MSE for classification\n",
    "\n",
    "#### 🏗️ **Practical Implementation**\n",
    "1. **PyTorch Fundamentals**: Building networks with `nn.Module`\n",
    "2. **Training Loops**: Forward pass, loss computation, backpropagation, parameter updates\n",
    "3. **Regularization**: Dropout and other techniques to prevent overfitting\n",
    "4. **Architecture Design**: How to choose layer sizes and activation functions\n",
    "\n",
    "#### 🌍 **Real-World Application**\n",
    "1. **Engineering Problem**: Earthquake liquefaction prediction\n",
    "2. **Feature Engineering**: Understanding domain-specific inputs\n",
    "3. **Model Comparison**: MLPs vs traditional methods (Decision Trees)\n",
    "4. **Performance Metrics**: Accuracy, AUC, confusion matrices, feature importance\n",
    "\n",
    "### Key Insights for Scientific Machine Learning\n",
    "\n",
    "#### Why MLPs Matter in Science and Engineering\n",
    "\n",
    "1. **Non-linear Pattern Recognition**: Many physical phenomena have complex, non-linear relationships\n",
    "2. **Feature Interaction Learning**: MLPs automatically discover how variables interact\n",
    "3. **Universal Approximation**: Theoretical guarantee that sufficient capacity can learn any pattern\n",
    "4. **Gradient-Based Optimization**: Efficient training even with millions of parameters\n",
    "\n",
    "#### Connection to Advanced SciML Methods\n",
    "\n",
    "This foundation enables understanding of:\n",
    "- **Physics-Informed Neural Networks (PINNs)**: MLPs that incorporate physical laws\n",
    "- **DeepONets**: Operator learning using MLP components\n",
    "- **Neural ODEs**: MLPs as function approximators in differential equations\n",
    "- **Graph Neural Networks**: MLPs applied to graph-structured scientific data\n",
    "\n",
    "### Performance Highlights\n",
    "\n",
    "Our MLP achieved:\n",
    "- **Better accuracy than decision trees** on complex non-linear patterns\n",
    "- **Probabilistic outputs** for uncertainty quantification\n",
    "- **Feature importance insights** through permutation analysis\n",
    "- **Robust performance** across different architectures\n",
    "\n",
    "### When to Use MLPs vs Alternatives\n",
    "\n",
    "**Use MLPs when:**\n",
    "- Complex, non-linear relationships expected\n",
    "- Large datasets available (1000+ samples)\n",
    "- Feature interactions are important\n",
    "- Probabilistic outputs needed\n",
    "- Building blocks for more complex architectures\n",
    "\n",
    "**Use alternatives when:**\n",
    "- Interpretability is critical (Decision Trees)\n",
    "- Very small datasets (< 100 samples)\n",
    "- Simple linear relationships (Linear models)\n",
    "- Computational resources are extremely limited\n",
    "\n",
    "### Next Steps in Your SciML Journey\n",
    "\n",
    "With this MLP foundation, you're ready to:\n",
    "1. **Explore deeper architectures** for more complex problems\n",
    "2. **Learn convolutional networks** for spatial data (images, fields)\n",
    "3. **Study recurrent networks** for temporal data (time series)\n",
    "4. **Understand Physics-Informed Neural Networks** for scientific applications\n",
    "5. **Apply transfer learning** to leverage pre-trained models\n",
    "\n",
    "The journey from perceptrons to modern scientific machine learning starts here! 🚀\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title, ax):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    im = ax.imshow(cm_normalized, cmap='Blues')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(['No Liquefaction', 'Liquefaction'])\n",
    "    ax.set_yticklabels(['No Liquefaction', 'Liquefaction'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            text = ax.text(j, i, f'{cm[i, j]}\\n({cm_normalized[i, j]:.3f})', \n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "# Create comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Confusion matrices\n",
    "plot_confusion_matrix(y_test, test_pred, 'MLP Confusion Matrix', axes[0, 0])\n",
    "plot_confusion_matrix(y_test, dt_pred, 'Decision Tree Confusion Matrix', axes[0, 1])\n",
    "\n",
    "# ROC curves\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, test_proba)\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, dt_proba)\n",
    "\n",
    "auc_mlp = roc_auc_score(y_test, test_proba)\n",
    "auc_dt = roc_auc_score(y_test, dt_proba)\n",
    "\n",
    "axes[1, 0].plot(fpr_mlp, tpr_mlp, 'b-', linewidth=2, label=f'MLP (AUC = {auc_mlp:.3f})')\n",
    "axes[1, 0].plot(fpr_dt, tpr_dt, 'r-', linewidth=2, label=f'Decision Tree (AUC = {auc_dt:.3f})')\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "axes[1, 0].set_xlabel('False Positive Rate')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "axes[1, 0].set_title('ROC Curves Comparison', fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall curves\n",
    "precision_mlp, recall_mlp, _ = precision_recall_curve(y_test, test_proba)\n",
    "precision_dt, recall_dt, _ = precision_recall_curve(y_test, dt_proba)\n",
    "\n",
    "axes[1, 1].plot(recall_mlp, precision_mlp, 'b-', linewidth=2, label='MLP')\n",
    "axes[1, 1].plot(recall_dt, precision_dt, 'r-', linewidth=2, label='Decision Tree')\n",
    "axes[1, 1].set_xlabel('Recall')\n",
    "axes[1, 1].set_ylabel('Precision')\n",
    "axes[1, 1].set_title('Precision-Recall Curves', fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAUC Comparison:\")\n",
    "print(f\"  MLP AUC:          {auc_mlp:.4f}\")\n",
    "print(f\"  Decision Tree AUC: {auc_dt:.4f}\")\n",
    "print(f\"  Improvement:      {((auc_mlp - auc_dt) / auc_dt * 100):+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding MLP Predictions: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mlp_feature_importance(model, X, y, feature_names, n_repeats=10):\n",
    "    \"\"\"Calculate feature importance using permutation method\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Baseline accuracy\n",
    "    with torch.no_grad():\n",
    "        baseline_pred = model.predict(X)\n",
    "        baseline_acc = (baseline_pred.flatten() == y.flatten()).float().mean().item()\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        feature_importances = []\n",
    "        \n",
    "        for _ in range(n_repeats):\n",
    "            # Create a copy of the data\n",
    "            X_permuted = X.clone()\n",
    "            \n",
    "            # Permute the i-th feature\n",
    "            perm_idx = torch.randperm(X_permuted.shape[0])\n",
    "            X_permuted[:, i] = X_permuted[perm_idx, i]\n",
    "            \n",
    "            # Calculate accuracy with permuted feature\n",
    "            with torch.no_grad():\n",
    "                permuted_pred = model.predict(X_permuted)\n",
    "                permuted_acc = (permuted_pred.flatten() == y.flatten()).float().mean().item()\n",
    "            \n",
    "            # Importance = decrease in accuracy\n",
    "            importance = baseline_acc - permuted_acc\n",
    "            feature_importances.append(importance)\n",
    "        \n",
    "        importances.append(np.mean(feature_importances))\n",
    "    \n",
    "    return np.array(importances)\n",
    "\n",
    "# Calculate feature importance for MLP\n",
    "feature_names = X_data.columns.tolist()  # Use X_data instead of X\n",
    "mlp_importances = calculate_mlp_feature_importance(model, X_test_tensor, y_test_tensor, feature_names)\n",
    "\n",
    "# Get decision tree feature importance for comparison\n",
    "dt_importances = dt_model.feature_importances_\n",
    "\n",
    "# Create comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# MLP feature importance\n",
    "indices = np.argsort(mlp_importances)[::-1]\n",
    "ax1.bar(range(len(mlp_importances)), mlp_importances[indices], color='blue', alpha=0.7)\n",
    "ax1.set_title('MLP Feature Importance\\\\n(Permutation Method)', fontweight='bold')\n",
    "ax1.set_xticks(range(len(feature_names)))\n",
    "ax1.set_xticklabels([feature_names[i] for i in indices], rotation=45)\n",
    "ax1.set_ylabel('Importance Score')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Decision tree feature importance\n",
    "indices_dt = np.argsort(dt_importances)[::-1]\n",
    "ax2.bar(range(len(dt_importances)), dt_importances[indices_dt], color='red', alpha=0.7)\n",
    "ax2.set_title('Decision Tree Feature Importance\\\\n(Gini Impurity)', fontweight='bold')\n",
    "ax2.set_xticks(range(len(feature_names)))\n",
    "ax2.set_xticklabels([feature_names[i] for i in indices_dt], rotation=45)\n",
    "ax2.set_ylabel('Importance Score')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance rankings\n",
    "print(\"Feature Importance Rankings:\")\n",
    "print(\"\\\\nMLP (Permutation):\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"  {i+1}. {feature_names[idx]}: {mlp_importances[idx]:.4f}\")\n",
    "\n",
    "print(\"\\\\nDecision Tree (Gini):\")\n",
    "for i, idx in enumerate(indices_dt):\n",
    "    print(f\"  {i+1}. {feature_names[idx]}: {dt_importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Architecture Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different architectures\n",
    "architectures = {\n",
    "    'Small': [32],\n",
    "    'Medium': [64, 32],\n",
    "    'Large': [128, 64, 32],\n",
    "    'Deep': [64, 64, 32, 16]\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Experimenting with different MLP architectures...\\n\")\n",
    "\n",
    "for name, hidden_sizes in architectures.items():\n",
    "    print(f\"Training {name} network: {hidden_sizes}\")\n",
    "    \n",
    "    # Create and train model\n",
    "    arch_model = MLPClassifier(input_size=4, hidden_sizes=hidden_sizes, dropout_rate=0.2)\n",
    "    arch_history = train_mlp_classifier(arch_model, X_train_tensor, y_train_tensor,\n",
    "                                       X_val_tensor, y_val_tensor,\n",
    "                                       epochs=500, lr=0.001, patience=30, verbose=False)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    arch_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_pred_arch = arch_model.predict(X_test_tensor).numpy().flatten()\n",
    "        test_proba_arch = arch_model.predict_proba(X_test_tensor).numpy().flatten()\n",
    "    \n",
    "    test_acc_arch = accuracy_score(y_test, test_pred_arch)\n",
    "    test_auc_arch = roc_auc_score(y_test, test_proba_arch)\n",
    "    \n",
    "    # Count parameters\n",
    "    n_params = sum(p.numel() for p in arch_model.parameters())\n",
    "    \n",
    "    results[name] = {\n",
    "        'architecture': hidden_sizes,\n",
    "        'accuracy': test_acc_arch,\n",
    "        'auc': test_auc_arch,\n",
    "        'parameters': n_params,\n",
    "        'final_val_loss': arch_history['val_loss'][-1]\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {test_acc_arch:.4f}, AUC: {test_auc_arch:.4f}, Parameters: {n_params}\\n\")\n",
    "\n",
    "# Create results comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Architecture Comparison:\")\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize architecture comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Accuracy vs Parameters\n",
    "architectures_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in architectures_names]\n",
    "parameters = [results[name]['parameters'] for name in architectures_names]\n",
    "aucs = [results[name]['auc'] for name in architectures_names]\n",
    "\n",
    "ax1.scatter(parameters, accuracies, s=100, alpha=0.7)\n",
    "for i, name in enumerate(architectures_names):\n",
    "    ax1.annotate(name, (parameters[i], accuracies[i]), \n",
    "                xytext=(5, 5), textcoords='offset points')\n",
    "ax1.set_xlabel('Number of Parameters')\n",
    "ax1.set_ylabel('Test Accuracy')\n",
    "ax1.set_title('Accuracy vs Model Complexity', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# AUC comparison\n",
    "ax2.bar(architectures_names, aucs, color='skyblue', alpha=0.7)\n",
    "ax2.set_ylabel('AUC Score')\n",
    "ax2.set_title('AUC Comparison Across Architectures', fontweight='bold')\n",
    "ax2.set_ylim(0.7, max(aucs) * 1.05)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for i, v in enumerate(aucs):\n",
    "    ax2.text(i, v + 0.005, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find best architecture\n",
    "best_arch = max(results.keys(), key=lambda x: results[x]['auc'])\n",
    "print(f\"\\nBest performing architecture: {best_arch}\")\n",
    "print(f\"Architecture: {results[best_arch]['architecture']}\")\n",
    "print(f\"AUC: {results[best_arch]['auc']:.4f}\")\n",
    "print(f\"Accuracy: {results[best_arch]['accuracy']:.4f}\")\n",
    "print(f\"Parameters: {results[best_arch]['parameters']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Insights\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. **MLP for Classification**: Successfully adapted the MLP architecture from function approximation to classification\n",
    "   - Same fundamental structure (input → hidden → output)\n",
    "   - Different loss function (Cross-Entropy vs MSE)\n",
    "   - Different output activation (Sigmoid vs Linear)\n",
    "\n",
    "2. **Performance Comparison**:\n",
    "   - MLP achieved comparable or better performance than Decision Trees\n",
    "   - MLPs can learn more complex, non-linear decision boundaries\n",
    "   - Feature importance patterns may differ between models\n",
    "\n",
    "3. **Architecture Design**:\n",
    "   - Deeper networks don't always perform better (diminishing returns)\n",
    "   - Parameter efficiency varies across architectures\n",
    "   - Regularization (dropout) helps prevent overfitting\n",
    "\n",
    "### MLP Advantages:\n",
    "- **Non-linear decision boundaries**: Can capture complex patterns\n",
    "- **Universal approximation**: Theoretical guarantee of representational power\n",
    "- **Gradient-based optimization**: Efficient training with backpropagation\n",
    "- **Scalability**: Can handle large datasets and high-dimensional features\n",
    "\n",
    "### MLP Disadvantages:\n",
    "- **Black box**: Less interpretable than decision trees\n",
    "- **Hyperparameter sensitivity**: Requires careful tuning\n",
    "- **Computational cost**: More expensive than simple models\n",
    "- **Overfitting risk**: Especially with limited data\n",
    "\n",
    "### When to Use MLPs vs Decision Trees:\n",
    "\n",
    "**Use MLPs when**:\n",
    "- Complex, non-linear patterns are expected\n",
    "- Large amounts of training data are available\n",
    "- High predictive accuracy is priority\n",
    "- Features have continuous, numerical values\n",
    "\n",
    "**Use Decision Trees when**:\n",
    "- Interpretability is crucial\n",
    "- Dataset is small or medium-sized\n",
    "- Features are mixed (categorical + numerical)\n",
    "- Simple, rule-based explanations are needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
